<!DOCTYPE html>
<!-- saved from url=(0037)https://zhuanlan.zhihu.com/p/66215918 -->
<html lang="zh-TW" data-hairline="true" data-theme="light" class="translated-ltr"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><title>CNN系列模型发展简述（附github代码——已全部跑通） - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="renderer" content="webkit"><meta name="force-rendering" content="webkit"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"><meta data-react-helmet="true" name="description" content="目录： 1 LeNet 2 AlexNet 3 VGG 4 GoogLeNet 5 ResNet 6 DenseNet 7 Non-Local Networks 8 Deformable Convolutional Networks 9 Dilated Convolutional Networks 10 SENETGITHUB(持续更新):liuyuemaicha/cnn_mod…"><meta data-react-helmet="true" property="og:title" content="CNN系列模型发展简述（附github代码——已全部跑通）"><meta data-react-helmet="true" property="og:url" content="https://zhuanlan.zhihu.com/p/66215918"><meta data-react-helmet="true" property="og:description" content="目录： 1 LeNet 2 AlexNet 3 VGG 4 GoogLeNet 5 ResNet 6 DenseNet 7 Non-Local Networks 8 Deformable Convolutional Networks 9 Dilated Convolutional Networks 10 SENETGITHUB(持续更新):liuyuemaicha/cnn_mod…"><meta data-react-helmet="true" property="og:image" content="https://pic2.zhimg.com/v2-faab9fd88ef1c02923dc9f4fda5b7a4d_b.jpg"><meta data-react-helmet="true" property="og:type" content="article"><meta data-react-helmet="true" property="og:site_name" content="知乎专栏"><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png"><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.67c7b278.png" sizes="152x152"><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.b3e6278d.png" sizes="120x120"><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.7a750095.png" sizes="76x76"><link data-react-helmet="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.a4a761d4.png" sizes="60x60"><link rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/static/favicon.ico"><link rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/static/search.xml" title="知乎"><link rel="dns-prefetch" href="https://static.zhimg.com/"><link rel="dns-prefetch" href="https://pic1.zhimg.com/"><link rel="dns-prefetch" href="https://pic2.zhimg.com/"><link rel="dns-prefetch" href="https://pic3.zhimg.com/"><link rel="dns-prefetch" href="https://pic4.zhimg.com/"><link href="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/app.0e32be8806e1e85f5de7.css" rel="stylesheet"><link rel="stylesheet"><script defer="" crossorigin="anonymous" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/init.js.下載" data-sentry-config="{&quot;dsn&quot;:&quot;https://65e244586890460588f00f2987137aa8@crash2.zhihu.com/193&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;1918-984bc963&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrors&quot;:[&quot;origin message&quot;,&quot;Network request failed&quot;,&quot;Loading chunk&quot;,&quot;这个系统不支持该功能。&quot;,&quot;Can&#39;t find variable: webkit&quot;,&quot;Can&#39;t find variable: $&quot;,&quot;内存不足&quot;,&quot;out of memory&quot;,&quot;DOM Exception 18&quot;,&quot;The operation is insecure&quot;,&quot;[object Event]&quot;,&quot;[object FileError]&quot;,&quot;[object DOMError]&quot;,&quot;[object Object]&quot;,&quot;拒绝访问。&quot;,&quot;Maximum call stack size exceeded&quot;,&quot;UploadError&quot;,&quot;无法 fetch&quot;,&quot;draft-js&quot;,&quot;缺少 JavaScript 对象&quot;,&quot;componentWillEnter&quot;,&quot;componentWillLeave&quot;,&quot;componentWillAppear&quot;,&quot;getInlineStyleAt&quot;,&quot;getCharacterList&quot;],&quot;whitelistUrls&quot;:[&quot;static.zhihu.com&quot;]}"></script><link rel="stylesheet" type="text/css" href="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/modals.eb20a50f09436979b01a.css"><script charset="utf-8" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/column.modals.2bda7eb925a4b7bc98b3.js.下載"></script><script src="chrome-extension://jhffgcfmcckgmioipfnmbannkpncfipo/util.js"></script><script src="chrome-extension://jhffgcfmcckgmioipfnmbannkpncfipo/pagejs.js"></script><link rel="stylesheet" type="text/css" href="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/richinput.4597be5e6911eaf2e794.css"><script charset="utf-8" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/column.richinput.f0bbcdb3cf480362ad3f.js.下載"></script><link type="text/css" rel="stylesheet" charset="UTF-8" href="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/translateelement.css"></head><body class="WhiteBg-body"><div id="root"><div class="App" data-reactroot=""><div class="LoadingBar"></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;&quot;}" data-zop="{&quot;authorName&quot;:&quot;KevinCK&quot;,&quot;itemId&quot;:66215918,&quot;title&quot;:&quot;CNN系列模型发展简述（附github代码——已全部跑通）&quot;,&quot;type&quot;:&quot;article&quot;}" data-za-detail-view-path-module="PostItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;token&quot;:&quot;66215918&quot;}}}"><div class="ColumnPageHeader-Wrapper"><div><div class="Sticky ColumnPageHeader" style=""><div class="ColumnPageHeader-content"><a href="https://www.zhihu.com/" aria-label="知乎"><svg viewBox="0 0 200 91" class="Icon ZhihuLogo ZhihuLogo--blue Icon--logo" style="height:30px;width:64px" width="64" height="30" aria-hidden="true"><title></title><g><path d="M53.29 80.035l7.32.002 2.41 8.24 13.128-8.24h15.477v-67.98H53.29v67.978zm7.79-60.598h22.756v53.22h-8.73l-8.718 5.473-1.587-5.46-3.72-.012v-53.22zM46.818 43.162h-16.35c.545-8.467.687-16.12.687-22.955h15.987s.615-7.05-2.68-6.97H16.807c1.09-4.1 2.46-8.332 4.1-12.708 0 0-7.523 0-10.085 6.74-1.06 2.78-4.128 13.48-9.592 24.41 1.84-.2 7.927-.37 11.512-6.94.66-1.84.785-2.08 1.605-4.54h9.02c0 3.28-.374 20.9-.526 22.95H6.51c-3.67 0-4.863 7.38-4.863 7.38H22.14C20.765 66.11 13.385 79.24 0 89.62c6.403 1.828 12.784-.29 15.937-3.094 0 0 7.182-6.53 11.12-21.64L43.92 85.18s2.473-8.402-.388-12.496c-2.37-2.788-8.768-10.33-11.496-13.064l-4.57 3.627c1.363-4.368 2.183-8.61 2.46-12.71H49.19s-.027-7.38-2.372-7.38zm128.752-.502c6.51-8.013 14.054-18.302 14.054-18.302s-5.827-4.625-8.556-1.27c-1.874 2.548-11.51 15.063-11.51 15.063l6.012 4.51zm-46.903-18.462c-2.814-2.577-8.096.667-8.096.667s12.35 17.2 12.85 17.953l6.08-4.29s-8.02-11.752-10.83-14.33zM199.99 46.5c-6.18 0-40.908.292-40.953.292v-31.56c1.503 0 3.882-.124 7.14-.376 12.773-.753 21.914-1.25 27.427-1.504 0 0 3.817-8.496-.185-10.45-.96-.37-7.24 1.43-7.24 1.43s-51.63 5.153-72.61 5.64c.5 2.756 2.38 5.336 4.93 6.11 4.16 1.087 7.09.53 15.36.277 7.76-.5 13.65-.76 17.66-.76v31.19h-41.71s.88 6.97 7.97 7.14h33.73v22.16c0 4.364-3.498 6.87-7.65 6.6-4.4.034-8.15-.36-13.027-.566.623 1.24 1.977 4.496 6.035 6.824 3.087 1.502 5.054 2.053 8.13 2.053 9.237 0 14.27-5.4 14.027-14.16V53.93h38.235c3.026 0 2.72-7.432 2.72-7.432z" fill-rule="evenodd"></path></g></svg></a><i class="ColumnPageHeader-Line"></i><div class="ColumnPageHeader-Title"><a class="ColumnLink ColumnPageHeader-Link" href="https://zhuanlan.zhihu.com/c_1123912990784966656"><img class="Avatar Avatar--round" width="30" height="30" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/4b70deef7_is.jpg" srcset="https://pic2.zhimg.com/4b70deef7_im.jpg 2x" alt="計算機視覺學習筆記"></a><div class="ColumnPageHeader-TitleName"><span class="ColumnPageHeader-TitleMeta"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">首發於</font></font></span><a class="ColumnLink ColumnPageHeader-TitleColumn" href="https://zhuanlan.zhihu.com/c_1123912990784966656"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">計算機視覺學習筆記</font></font></a></div></div><div class="ColumnPageHeader-Button"><button type="button" class="Button FollowButton ColumnPageHeader-FollowButton Button--primary Button--blue"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">關注專欄</font></font></button><button type="button" class="Button ColumnPageHeader-WriteButton Button--blue"><svg class="Zi Zi--EditSurround" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M18.453 7.992l-1.833-1.65.964-.978a1.223 1.223 0 0 1 1.73-.012l.005.006a1.24 1.24 0 0 1 .007 1.748l-.873.886zm-1.178 1.194l-5.578 5.66-1.935.697a.393.393 0 0 1-.504-.504l.697-1.935 5.488-5.567 1.832 1.65zM7.58 5.848l5.654.006-1.539 1.991-3.666.012A1.02 1.02 0 0 0 7 8.868v7.993c0 .558.46 1.01 1.029 1.01l7.941-.01c.568 0 1.03-.453 1.03-1.012v-4.061l2-1.442v6.002c0 1.397-1.2 2.501-2.62 2.501H7.574C6.153 19.85 5 18.717 5 17.32V8.35c0-1.397 1.16-2.502 2.58-2.502z"></path></svg><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">寫文章</font></font></button></div></div></div></div></div><img class="TitleImage" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-faab9fd88ef1c02923dc9f4fda5b7a4d_1200x500.jpg" alt="CNN系列模型發展簡述（附github代碼——已全部跑通）"><article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN系列模型發展簡述（附github代碼——已全部跑通）</font></font></h1><div class="Post-Author"><div class="AuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="name" content="KevinCK"><meta itemprop="image" content="https://pic4.zhimg.com/0a900ad0d691e76a0ba1d5a5306698a1_is.jpg"><meta itemprop="url" content="https://www.zhihu.com/people/liuyuemaicha"><meta itemprop="zhihu:followerCount" content="3512"><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="Popover2-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover2-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/liuyuemaicha"><img class="Avatar Avatar--round AuthorInfo-avatar" width="38" height="38" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/0a900ad0d691e76a0ba1d5a5306698a1_xs.jpg" srcset="https://pic4.zhimg.com/0a900ad0d691e76a0ba1d5a5306698a1_l.jpg 2x" alt="KevinCK"></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="Popover3-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover3-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/liuyuemaicha"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">KevinCK</font></font></a></div></div><a class="UserLink-badge" data-tooltip="已认证的个人" href="https://www.zhihu.com/question/48510028" target="_blank"><span style="display:inline-flex;align-items:center"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--BadgeCert" fill="currentColor" viewBox="0 0 24 24" width="18" height="18"><g fill="none" fill-rule="evenodd"><path fill="#0F88EB" d="M2.64 13.39c1.068.895 1.808 2.733 1.66 4.113l.022-.196c-.147 1.384.856 2.4 2.24 2.278l-.198.016c1.387-.122 3.21.655 4.083 1.734l-.125-.154c.876 1.084 2.304 1.092 3.195.027l-.127.152c.895-1.068 2.733-1.808 4.113-1.66l-.198-.022c1.386.147 2.402-.856 2.279-2.238l.017.197c-.122-1.388.655-3.212 1.734-4.084l-.154.125c1.083-.876 1.092-2.304.027-3.195l.152.127c-1.068-.895-1.808-2.732-1.66-4.113l-.022.198c.147-1.386-.856-2.4-2.24-2.279l.198-.017c-1.387.123-3.21-.654-4.083-1.733l.125.153c-.876-1.083-2.304-1.092-3.195-.027l.127-.152c-.895 1.068-2.733 1.808-4.113 1.662l.198.02c-1.386-.147-2.4.857-2.279 2.24L4.4 6.363c.122 1.387-.655 3.21-1.734 4.084l.154-.126c-1.083.878-1.092 2.304-.027 3.195l-.152-.127z"></path><path fill="#FFF" d="M9.78 15.728l-2.633-2.999s-.458-.705.242-1.362c.7-.657 1.328-.219 1.328-.219l1.953 2.132 4.696-4.931s.663-.348 1.299.198c.636.545.27 1.382.27 1.382s-3.466 3.858-5.376 5.782c-.98.93-1.778.017-1.778.017z"></path></g></svg></span></a></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="AuthorInfo-badgeText"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">百度計算機視覺工程師</font></font></div></div></div></div></div></div><div><span class="Voters"><button type="button" class="Button Button--plain"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">318人</font></font><!-- --><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">讚同了該文章</font></font></button></span></div></header><div class="Post-RichTextContainer"><div class="RichText ztext Post-RichText" ecommerce="[object Object]"><blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">目錄：</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1 LeNet </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2 AlexNet </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3 VGG </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4 GoogLeNet </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">5 ResNet </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">6 DenseNet </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">7 Non-Local Networks </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8 Deformable Convolutional Networks </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">9 Dilated Convolutional Networks </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">10 SENET</font></font></blockquote><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">GITHUB(持續更新):</font></font></h2><a target="_blank" href="https://link.zhihu.com/?target=https%3A//github.com/liuyuemaicha/cnn_model" data-draft-node="block" data-draft-type="link-card" data-image="https://pic4.zhimg.com/v2-be7f59346f9400a5e76e0e4bca873897_ipico.jpg" data-image-width="400" data-image-height="400" class="LinkCard LinkCard--hasImage" data-za-detail-view-id="172"><span class="LinkCard-backdrop" style="background-image:url(https://pic4.zhimg.com/v2-be7f59346f9400a5e76e0e4bca873897_ipico.jpg)"></span><span class="LinkCard-content"><span class="LinkCard-text"><span class="LinkCard-title" data-text="true"><font style="vertical-align: inherit;"></font></span><font style="vertical-align: inherit;"><span class="LinkCard-meta"><font style="vertical-align: inherit;">liuyuemaicha/cnn_model​github.com</font></span></font><span class="LinkCard-meta"><span style="display:inline-flex;align-items:center"><font style="vertical-align: inherit;"></font><svg class="Zi Zi--InsertLink" fill="currentColor" viewBox="0 0 24 24" width="17" height="17"><path d="M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"></font></span></span><span class="LinkCard-imageCell"><img class="LinkCard-image LinkCard-image--square" alt="圖標" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-be7f59346f9400a5e76e0e4bca873897_ipico.jpg"></span></span></a><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">github代碼依賴： python 2.7, Pytorch 0.3.1</font></font></h2><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1 LeNet</font></font></h2><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">LeNet雖然不是CNN的起點，但卻是後來CNN興起的標誌模型。</font><font style="vertical-align: inherit;">LeNet-5是1998年YannLeCun設計用於手寫數字識別的模型。</font></font></p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-bd5a9c288d4d9e26be5674a0bfac3ba1_b.jpg" data-size="normal" data-rawwidth="700" data-rawheight="193" class="origin_image zh-lightbox-thumb" width="700" data-original="https://pic2.zhimg.com/v2-bd5a9c288d4d9e26be5674a0bfac3ba1_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-bd5a9c288d4d9e26be5674a0bfac3ba1_hd.jpg" data-size="normal" data-rawwidth="700" data-rawheight="193" class="origin_image zh-lightbox-thumb lazy" width="700" data-original="https://pic2.zhimg.com/v2-bd5a9c288d4d9e26be5674a0bfac3ba1_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-bd5a9c288d4d9e26be5674a0bfac3ba1_b.jpg"><figcaption><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">圖1.1：LeNet-5網絡結構</font></font></figcaption></figure><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-e5b242d3cccd26c8eb395d15081bc0e3_b.jpg" data-size="normal" data-rawwidth="416" data-rawheight="362" class="content_image" width="416"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-e5b242d3cccd26c8eb395d15081bc0e3_hd.jpg" data-size="normal" data-rawwidth="416" data-rawheight="362" class="content_image lazy" width="416" data-actualsrc="https://pic4.zhimg.com/v2-e5b242d3cccd26c8eb395d15081bc0e3_b.jpg"><figcaption><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">圖1.2：LeNet-5網絡結構</font></font></figcaption></figure><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在當年神經網絡還是MLP（Multilayer Perceptron，多層感知機）大行其道時，能設計出這樣的模型已實屬不易，也為後來CNN模型的發展奠定了基礎。</font></font></p><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">特點：</font></font></p><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1.相比MLP，LeNet使用了相對更少的參數，獲得了更好的結果。</font></font></p><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2.設計了maxpool來提取特徵</font></font></p><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2 AlexNet</font></font></h2><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AlexNet是Hinton和他的學生Alex在2012設計的網絡，並獲得了當年的ImageNet競賽冠軍。</font></font></p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-51828e6a40c2a8fe150aefdf6a7a5fec_b.jpg" data-size="normal" data-rawwidth="1080" data-rawheight="366" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-51828e6a40c2a8fe150aefdf6a7a5fec_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-51828e6a40c2a8fe150aefdf6a7a5fec_hd.jpg" data-size="normal" data-rawwidth="1080" data-rawheight="366" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-51828e6a40c2a8fe150aefdf6a7a5fec_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-51828e6a40c2a8fe150aefdf6a7a5fec_b.jpg"><figcaption><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">圖2.1: AlexNet網絡</font></font></figcaption></figure><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-3f20a882478729c6ccf48c9e47541ffb_b.jpg" data-size="normal" data-rawwidth="446" data-rawheight="692" class="origin_image zh-lightbox-thumb" width="446" data-original="https://pic4.zhimg.com/v2-3f20a882478729c6ccf48c9e47541ffb_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-3f20a882478729c6ccf48c9e47541ffb_hd.jpg" data-size="normal" data-rawwidth="446" data-rawheight="692" class="origin_image zh-lightbox-thumb lazy" width="446" data-original="https://pic4.zhimg.com/v2-3f20a882478729c6ccf48c9e47541ffb_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-3f20a882478729c6ccf48c9e47541ffb_b.jpg"><figcaption><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">圖2.2: AlexNet網絡</font></font></figcaption></figure><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">特點：</font></font></p><p>1.相比LeNet，AlexNet设计了更深层的网络。</p><p>2.在每个卷机后面添加了Relu激活函数，解决了Sigmoid的梯度消失问题，使收敛更快。</p><p>3.添加了归一化LRN（Local Response Normalization，局部响应归一化）层，使准确率更高。</p><p>4. 设计并使用了dropout层，减轻了模型的过拟合。</p><p>5.通过裁剪，旋转等方式增强了训练数据。</p><p>6.受于当时的算力限制，Alexnet创新地将图像分为上下两块分别训练，然后在全连接层合并在一起（AlexNet网络图1，可以看到有上下两部分）。</p><h2>3 VGGNet</h2><p>VGGNet在2014年的ImageNet比赛中，分别在定位和分类跟踪任务中取得第一名和第二名。VGGNet主要特点：</p><p>1.探索了更深层次的网络结构图，可以看成是AlexNet的加强版本。</p><p>2.在卷机设计上，使用了更小的卷机核，验证了小尺寸的卷机核在深度网络中，不仅减少了参数，也达到了更好的效果。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-ab442f19d6e2328ac721cf8e552d04a9_b.jpg" data-size="normal" data-rawwidth="1044" data-rawheight="988" class="origin_image zh-lightbox-thumb" width="1044" data-original="https://pic2.zhimg.com/v2-ab442f19d6e2328ac721cf8e552d04a9_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-ab442f19d6e2328ac721cf8e552d04a9_hd.jpg" data-size="normal" data-rawwidth="1044" data-rawheight="988" class="origin_image zh-lightbox-thumb lazy" width="1044" data-original="https://pic2.zhimg.com/v2-ab442f19d6e2328ac721cf8e552d04a9_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-ab442f19d6e2328ac721cf8e552d04a9_b.jpg"><figcaption>图3.1: VGGNet网络结构图</figcaption></figure><h2>4 GoogLeNet</h2><p><b>4.1 GoogLeNet v1</b></p><p>GoogLeNet v1版本诞生于2014年，在ILSVRC 比赛中获得冠军，其性能与同年诞生的VGG差不多，但参数量少于VGG。该模型并没有单纯的将网络加深，而是引入了Inception概念，<b>通过多个卷积核提取图像不同尺度的信息，最后进行融合，可以得到图像更好的表征</b>。</p><p>特点：</p><p>1.引入Inception概念，在当时流行模型‘加深’情况下，设计了‘加宽’的思路</p><p>2.采用Network in Network中用Average pool来代替全连接层的思想。实际在最后一层还是添加了一个全连接层，是为了大家做finetune。</p><p>3.另外增加了两个辅助的softmax分支，作用有两点，一是为了避免梯度消失，用于向前传导梯度。反向传播时如果有一层求导为0，链式求导结果则为0。二是将中间某一层输出用作分类，起到模型融合作用。最后的loss=loss_2 + 0.3 * loss_1 + 0.3 * loss_0。实际测试时，这两个辅助softmax分支会被去掉。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-b3731d293a7775eab0203e4e0182b5d8_b.jpg" data-size="normal" data-rawwidth="324" data-rawheight="284" class="content_image" width="324"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-b3731d293a7775eab0203e4e0182b5d8_hd.jpg" data-size="normal" data-rawwidth="324" data-rawheight="284" class="content_image lazy" width="324" data-actualsrc="https://pic1.zhimg.com/v2-b3731d293a7775eab0203e4e0182b5d8_b.jpg"><figcaption>图4.1: Inception</figcaption></figure><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-54468fc87ff65a25950db4f2dd8059a6_b.jpg" data-size="normal" data-rawwidth="716" data-rawheight="410" class="origin_image zh-lightbox-thumb" width="716" data-original="https://pic3.zhimg.com/v2-54468fc87ff65a25950db4f2dd8059a6_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-54468fc87ff65a25950db4f2dd8059a6_hd.jpg" data-size="normal" data-rawwidth="716" data-rawheight="410" class="origin_image zh-lightbox-thumb lazy" width="716" data-original="https://pic3.zhimg.com/v2-54468fc87ff65a25950db4f2dd8059a6_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-54468fc87ff65a25950db4f2dd8059a6_b.jpg"><figcaption>图4.2</figcaption></figure><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-4a5d576e354b8d45b7e8c6a5b9880dc7_b.jpg" data-size="normal" class="content_image"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-4a5d576e354b8d45b7e8c6a5b9880dc7_hd.jpg" data-size="normal" class="content_image lazy" data-actualsrc="https://pic4.zhimg.com/v2-4a5d576e354b8d45b7e8c6a5b9880dc7_b.jpg"><figcaption>图4.3: GoogLeNet V1整体结构</figcaption></figure><p><b>4.2 GoogLeNet V2，V3</b></p><p>在2015年，同篇论文中发布了 GoogLeNet V2和V3版本。</p><p>V2特点：</p><ol><li>学习VGGNet的特点，用两个3*3卷积代替5*5卷积，降低参数量，提高计算速度，从而提升性能。（下图Figure5）</li><li>它们将滤波器大小nxn的卷积分解为1xn和nx1卷积的组合。例如，3x3卷积相当于首先执行1x3卷积，然后在其输出上执行3x1卷积。他们发现这种方法比单个3x3卷积便宜33％。（下图Figure6）</li><li>模块中的滤波器组被扩展（更宽而不是更深）以消除代表性瓶颈。如果模块变得更深，则尺寸会过度减少，从而导致信息丢失。（下图Figure7）</li></ol><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-74df852aea1b456a221a770baf29f5eb_b.jpg" data-size="normal" data-rawwidth="1278" data-rawheight="394" class="origin_image zh-lightbox-thumb" width="1278" data-original="https://pic4.zhimg.com/v2-74df852aea1b456a221a770baf29f5eb_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-74df852aea1b456a221a770baf29f5eb_hd.jpg" data-size="normal" data-rawwidth="1278" data-rawheight="394" class="origin_image zh-lightbox-thumb lazy" width="1278" data-original="https://pic4.zhimg.com/v2-74df852aea1b456a221a770baf29f5eb_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-74df852aea1b456a221a770baf29f5eb_b.jpg"><figcaption>图4.4: 3种Inception结构</figcaption></figure><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-f9e7addb312fe206538f519eb489a3f2_b.jpg" data-size="normal" data-rawwidth="592" data-rawheight="514" class="origin_image zh-lightbox-thumb" width="592" data-original="https://pic3.zhimg.com/v2-f9e7addb312fe206538f519eb489a3f2_r.jpg"/></noscript><span><div class="VagueImage origin_image zh-lightbox-thumb" data-src="https://pic3.zhimg.com/80/v2-f9e7addb312fe206538f519eb489a3f2_hd.jpg" style="width: 592px; height: 514px;"><div class="VagueImage-mask is-active"></div></div></span><figcaption>图4.5: GoogLeNet v2结构</figcaption></figure><p>V3包含了为V2规定的所有上述改进，另外还使用了以下内容：</p><ol><li>RMSProp优化器。</li><li>学习Factorization into small convolutions的思想，将7x7分解成两个一维的卷积（1x7,7x1），3x3也是一样（1x3,3x1），这样的好处，既可以加速计算（多余的计算能力可以用来加深网络），又可以将1个conv拆成2个conv，使得网络深度进一步增加，增加了网络的非线性，还有值得注意的地方是网络输入从224x224变为了299x299，更加精细设计了35x35/17x17/8x8的模块。</li><li>辅助分类器中的BatchNorm。BN算法是一个正则化方法，可以提高大网络的收敛速度。简单介绍一下BN算法。就是对输入层信息分布标准化处理，使得规范化为N(0,1)的高斯分布，收敛速度大大提高。</li><li>标签平滑（添加到损失公式中的一种正规化组件，可防止网络对类过于自信。防止过度拟合）。</li></ol><p><b>4.3 GoogLeNet V4 ，Inception-ResNet v1和v2</b></p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-bbe93e6e4a1689ce0aba0eb18b0728f7_b.jpg" data-size="normal" data-rawwidth="1574" data-rawheight="468" class="origin_image zh-lightbox-thumb" width="1574" data-original="https://pic4.zhimg.com/v2-bbe93e6e4a1689ce0aba0eb18b0728f7_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-bbe93e6e4a1689ce0aba0eb18b0728f7_hd.jpg" data-size="normal" data-rawwidth="1574" data-rawheight="468" class="origin_image zh-lightbox-thumb lazy" width="1574" data-original="https://pic4.zhimg.com/v2-bbe93e6e4a1689ce0aba0eb18b0728f7_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-bbe93e6e4a1689ce0aba0eb18b0728f7_b.jpg"><figcaption>图4.6: V4版本 3种Inception结构</figcaption></figure><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-ad457161f29b2dc6823df321b3e5e865_b.jpg" data-size="normal" data-rawwidth="2360" data-rawheight="568" class="origin_image zh-lightbox-thumb" width="2360" data-original="https://pic2.zhimg.com/v2-ad457161f29b2dc6823df321b3e5e865_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-ad457161f29b2dc6823df321b3e5e865_hd.jpg" data-size="normal" data-rawwidth="2360" data-rawheight="568" class="origin_image zh-lightbox-thumb lazy" width="2360" data-original="https://pic2.zhimg.com/v2-ad457161f29b2dc6823df321b3e5e865_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-ad457161f29b2dc6823df321b3e5e865_b.jpg"><figcaption>图4.7: 4种Reduction结构</figcaption></figure><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-b029fbbf770f13cfb7590471f80e5c18_b.jpg" data-size="normal" data-rawwidth="1800" data-rawheight="668" class="origin_image zh-lightbox-thumb" width="1800" data-original="https://pic1.zhimg.com/v2-b029fbbf770f13cfb7590471f80e5c18_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-b029fbbf770f13cfb7590471f80e5c18_hd.jpg" data-size="normal" data-rawwidth="1800" data-rawheight="668" class="origin_image zh-lightbox-thumb lazy" width="1800" data-original="https://pic1.zhimg.com/v2-b029fbbf770f13cfb7590471f80e5c18_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-b029fbbf770f13cfb7590471f80e5c18_b.jpg"><figcaption>图4.8: 3种Inception-ResNet-V1结构</figcaption></figure><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-c67390a307425fc2b136fce45df4a80f_b.jpg" data-size="normal" data-rawwidth="1736" data-rawheight="752" class="origin_image zh-lightbox-thumb" width="1736" data-original="https://pic4.zhimg.com/v2-c67390a307425fc2b136fce45df4a80f_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-c67390a307425fc2b136fce45df4a80f_hd.jpg" data-size="normal" data-rawwidth="1736" data-rawheight="752" class="origin_image zh-lightbox-thumb lazy" width="1736" data-original="https://pic4.zhimg.com/v2-c67390a307425fc2b136fce45df4a80f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-c67390a307425fc2b136fce45df4a80f_b.jpg"><figcaption>图4.9: 3种Inception-ResNet-V2结构</figcaption></figure><figure data-size="small"><noscript><img src="https://pic2.zhimg.com/v2-6ba76fea791d6571e4801495697163e1_b.jpg" data-size="small" data-rawwidth="1222" data-rawheight="1008" class="origin_image zh-lightbox-thumb" width="1222" data-original="https://pic2.zhimg.com/v2-6ba76fea791d6571e4801495697163e1_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-6ba76fea791d6571e4801495697163e1_hd.jpg" data-size="small" data-rawwidth="1222" data-rawheight="1008" class="origin_image zh-lightbox-thumb lazy" width="1222" data-original="https://pic2.zhimg.com/v2-6ba76fea791d6571e4801495697163e1_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-6ba76fea791d6571e4801495697163e1_b.jpg"><figcaption>图4.10: Inception-ResNet结构中加入 Activation Scaling，防止网络“死亡”</figcaption></figure><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-b545bd70798a1efe3ae0e4ab5eee6f0b_b.jpg" data-size="normal" data-rawwidth="2436" data-rawheight="1234" class="origin_image zh-lightbox-thumb" width="2436" data-original="https://pic4.zhimg.com/v2-b545bd70798a1efe3ae0e4ab5eee6f0b_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-b545bd70798a1efe3ae0e4ab5eee6f0b_hd.jpg" data-size="normal" data-rawwidth="2436" data-rawheight="1234" class="origin_image zh-lightbox-thumb lazy" width="2436" data-original="https://pic4.zhimg.com/v2-b545bd70798a1efe3ae0e4ab5eee6f0b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-b545bd70798a1efe3ae0e4ab5eee6f0b_b.jpg"><figcaption>4.11: Stem与最终网络结构图</figcaption></figure><p><b>V4与之前的V3，V2版本主要改动有：</b></p><ol><li>修改了stem，这里的stem是指在引入Inception块之前执行的初始操作集。</li><li>V4引入了专门的“Reduction Blocks”，用于改变网格的宽度和高度。早期版本没有显式Reduction Blocks，但实现了类似功能。</li><li>V4版本的3种Inception与之前版本的3种Inception非常相似，但也做了细节的修改。</li></ol><p><b>Inception-ResNet V1和V2特点：</b></p><ol><li>在Inception设计中加入了ResNet思想。从图4.8和图4.9可以看到，V1和V2中的3种Inception-ResNet结构相同，不同的只是超参数。</li><li>Inception-ResNet V1与V2的整体结构不同，Inception-ResNet V1的计算成本与Inception v3类似，Inception-ResNet V2的计算成本与Inception v4类似。</li><li>为了实现残差加法，卷积后的输入和输出必须具有相同的尺寸。因此，我们在Inception卷积之后使用1x1卷积来匹配深度大小（卷积后的深度增加）。</li><li>主要Inception模块内的池化操作被替换为有利于残差连接。但是，您仍然可以在reduction blocks中找到这些操作。Reduction Block A与Inception v4中的相同。</li><li>如果滤波器的数量超过1000，那么网络架构中更深的残差单元会导致网络“死亡”。因此，为了增加稳定性，作者将残差激活量调整，系数为0.1到0.3，如图4.10。</li><li>为了在单个GPU上训练模型，原始论文在求和之后没有使用BatchNorm（以使整个模型适合单个GPU）。</li><li>结果发现，Inception-ResNet模型能够再用较少的epoch时获得更高的精度。</li></ol><h2>5 ResNet</h2><p>随着算力的不断更新，越来越深的网络能够得到计算，但研究者发现随着网络的加深，模型变得越来越不能够训练，遇到了梯度消失或爆炸问题。在ResNet出现之前，人们通过BN，Relu等方式去缓解此问题，但仍然不能把网络做到足够深。</p><p>15年何恺明提出了ResNet网络，该思路启发于LSTM的控制门的思想。</p><blockquote>y = H(x,WH)•T(x,WT) + X•(1- T(x,WT)) </blockquote><p>可以看出，当T(x,WT) = 0，y=x，当T(x,WT) = 1，y= H(x,WH) </p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-6dd1d0a92ec60e33a5a13074e8108c6e_b.jpg" data-size="normal" data-rawwidth="438" data-rawheight="242" class="origin_image zh-lightbox-thumb" width="438" data-original="https://pic3.zhimg.com/v2-6dd1d0a92ec60e33a5a13074e8108c6e_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-6dd1d0a92ec60e33a5a13074e8108c6e_hd.jpg" data-size="normal" data-rawwidth="438" data-rawheight="242" class="origin_image zh-lightbox-thumb lazy" width="438" data-original="https://pic3.zhimg.com/v2-6dd1d0a92ec60e33a5a13074e8108c6e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-6dd1d0a92ec60e33a5a13074e8108c6e_b.jpg"><figcaption>图5.1 ResNet中的block示意图</figcaption></figure><p>从图5.1可以看出：相比传统网络：y=f(x)，ResNet Block公式为：y=f(x) + x，可以称之为skip connect。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-30457c8c79506a27ca7756b82a7b2730_b.jpg" data-size="normal" data-rawwidth="808" data-rawheight="404" class="origin_image zh-lightbox-thumb" width="808" data-original="https://pic1.zhimg.com/v2-30457c8c79506a27ca7756b82a7b2730_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-30457c8c79506a27ca7756b82a7b2730_hd.jpg" data-size="normal" data-rawwidth="808" data-rawheight="404" class="origin_image zh-lightbox-thumb lazy" width="808" data-original="https://pic1.zhimg.com/v2-30457c8c79506a27ca7756b82a7b2730_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-30457c8c79506a27ca7756b82a7b2730_b.jpg"><figcaption>图5.2 ResNet网络中使用的两种Block</figcaption></figure><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-7aaa9fb90e2546cbc185893eed067a99_b.jpg" data-size="normal" data-rawwidth="1474" data-rawheight="514" class="origin_image zh-lightbox-thumb" width="1474" data-original="https://pic2.zhimg.com/v2-7aaa9fb90e2546cbc185893eed067a99_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-7aaa9fb90e2546cbc185893eed067a99_hd.jpg" data-size="normal" data-rawwidth="1474" data-rawheight="514" class="origin_image zh-lightbox-thumb lazy" width="1474" data-original="https://pic2.zhimg.com/v2-7aaa9fb90e2546cbc185893eed067a99_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-7aaa9fb90e2546cbc185893eed067a99_b.jpg"><figcaption>图5.3 不同层数的ResNet设计方式</figcaption></figure><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-4d0409256153f441477f9483ffc88a80_b.jpg" data-size="normal" data-rawwidth="1080" data-rawheight="424" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-4d0409256153f441477f9483ffc88a80_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-4d0409256153f441477f9483ffc88a80_hd.jpg" data-size="normal" data-rawwidth="1080" data-rawheight="424" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-4d0409256153f441477f9483ffc88a80_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-4d0409256153f441477f9483ffc88a80_b.jpg"><figcaption>图5.4 34层ResNet与其他网络的比较</figcaption></figure><p><b>题外话：</b></p><p>Orhan等发表的论文《Skip connections eliminate singularities》提出<b>神经网络的退化才是难以训练深层网络根本原因所在，而不是梯度消散</b>。虽然梯度范数大，但是如果网络的可用自由度对这些范数的贡献非常不均衡，也就是每个层中只有少量的隐藏单元对不同的输入改变它们的激活值，而大部分隐藏单元对不同的输入都是相同的反应，此时整个权重矩阵的秩不高。并且随着网络层数的增加，连乘后使得整个秩变的更低。这也是我们常说的网络退化问题，虽然是一个很高维的矩阵，但是大部分维度却没有信息，表达能力没有看起来那么强大。残差连接正是强制打破了网络的对称性。总的来说一句话，打破了网络的对称性，提升了网络的表征能力。也可查看文献《Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units》。</p><h2><b>6 DenseNet</b></h2><p>从图6.1中可以看出，DenseNet是借鉴了ResNet，是ResNet的升级版，从上述ResNet可以看到，一般每个Block会有一个skip connect，而DenseNet会在每层conv间有一个skip connect。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-5f7997b4679018b284834cad140d366d_b.jpg" data-size="normal" data-rawwidth="1152" data-rawheight="436" class="origin_image zh-lightbox-thumb" width="1152" data-original="https://pic2.zhimg.com/v2-5f7997b4679018b284834cad140d366d_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-5f7997b4679018b284834cad140d366d_hd.jpg" data-size="normal" data-rawwidth="1152" data-rawheight="436" class="origin_image zh-lightbox-thumb lazy" width="1152" data-original="https://pic2.zhimg.com/v2-5f7997b4679018b284834cad140d366d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-5f7997b4679018b284834cad140d366d_b.jpg"><figcaption>图6.1 ResNet Block与DenseNetBlock区别</figcaption></figure><figure data-size="small"><noscript><img src="https://pic4.zhimg.com/v2-64d758c01b0578e9004bc725f7eb7b03_b.jpg" data-size="small" data-rawwidth="688" data-rawheight="578" class="origin_image zh-lightbox-thumb" width="688" data-original="https://pic4.zhimg.com/v2-64d758c01b0578e9004bc725f7eb7b03_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-64d758c01b0578e9004bc725f7eb7b03_hd.jpg" data-size="small" data-rawwidth="688" data-rawheight="578" class="origin_image zh-lightbox-thumb lazy" width="688" data-original="https://pic4.zhimg.com/v2-64d758c01b0578e9004bc725f7eb7b03_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-64d758c01b0578e9004bc725f7eb7b03_b.jpg"><figcaption>图6.2DenseNet Block示意图</figcaption></figure><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-a8a812f9cac80ff5da05b5de34ff019e_b.jpg" data-size="normal" data-rawwidth="1196" data-rawheight="558" class="origin_image zh-lightbox-thumb" width="1196" data-original="https://pic3.zhimg.com/v2-a8a812f9cac80ff5da05b5de34ff019e_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-a8a812f9cac80ff5da05b5de34ff019e_hd.jpg" data-size="normal" data-rawwidth="1196" data-rawheight="558" class="origin_image zh-lightbox-thumb lazy" width="1196" data-original="https://pic3.zhimg.com/v2-a8a812f9cac80ff5da05b5de34ff019e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-a8a812f9cac80ff5da05b5de34ff019e_b.jpg"><figcaption>图6.3 DenseNet 各网络结构图</figcaption></figure><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-f0c92f93668b600c04643bb8b65a7790_b.jpg" data-size="normal" data-rawwidth="1680" data-rawheight="326" class="origin_image zh-lightbox-thumb" width="1680" data-original="https://pic1.zhimg.com/v2-f0c92f93668b600c04643bb8b65a7790_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-f0c92f93668b600c04643bb8b65a7790_hd.jpg" data-size="normal" data-rawwidth="1680" data-rawheight="326" class="origin_image zh-lightbox-thumb lazy" width="1680" data-original="https://pic1.zhimg.com/v2-f0c92f93668b600c04643bb8b65a7790_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-f0c92f93668b600c04643bb8b65a7790_b.jpg"><figcaption>图6.4 DenseNet 网络</figcaption></figure><blockquote>神经网络越深，网络的能力越强，就越有可能过度学习数据集，导致过拟合。大家应该还记得，作为第一个深层网络Alexnet网络，它提出了重要的策略dropout，对于提高模型的泛化能力非常有效。alexnet网络至今仍然可以用于很多的任务，这足以说明其鲁棒性。后来BN和数据增强等正则化策略替代dropout也在一定程度上缓解了过拟合的问题。文《Deep networks with stochastic depth》（Huang G, Sun Y, Liu Z, et al. ）是DenseNet作者们早期的研究，它们通过训练时随机丢掉一些网络层，提高了ResNet的泛化性能。<br>从这里可以看出来一个重要特性，这也是神经网络中大家比较关心的问题，<b>网络的冗余性绝对是存在的，而且不小</b>，通过探索dropout值的比例对性能的影响可以去估算这个冗余。<br>既然丢掉某些层间连接或者整个层不影响性能，就说明这一层学习到的非线性转变很小，既然转变很小，那么每一层学习几百个通道，还有必要吗？这几百个通道，正是万恶的计算量所在。<br><b>考虑到这一点，densenet就同时做了两件事情，一是将网络中的每一层都直接与其前面层相连，提高特征的利用率；二是把网络的每一层设计得很窄，也就是卷积的输出通道数通常很小，只有几十，该层学习非常少的特征图并与输入concat使用。</b><br>这实现了资源的最大化利用和计算量的压缩。ImageNet分类数据集上达到同样的准确率，DenseNet 所需的参数量不到ResNet的一半，所需的计算量也只有ResNet的一半左右。<br>引用自<a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer" data-za-detail-view-id="1043">【模型解读】“全连接”的卷积网络，有什么好？</a></blockquote><h2>7 Non-Local Networks</h2><p>Non-Local Networks启发于non-local means滤波算法，该滤波算法是经典的图像去噪算法之一。在CNN模型中不论是conv层还是pool层（全局pool除外），它们对数据的感受野都是局部的。为了增大conv或pool的感受野，传统方式是增加网络的深度（网络越深，后面conv和pool的感受野越大），但这样会增加训练的难度（越深越难训练），而且降低效率（参数增加）。该论文提出的Non-local Networks可以在每层计算中参考全局信息。</p><p>该方法属于<b>自注意力机制</b>的范畴</p><p class="ztext-empty-paragraph"><br></p><figure data-size="small"><noscript><img src="https://pic3.zhimg.com/v2-001eea370bb4350424ae6be8c440c5be_b.jpg" data-size="small" data-rawwidth="1080" data-rawheight="1038" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-001eea370bb4350424ae6be8c440c5be_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-001eea370bb4350424ae6be8c440c5be_hd.jpg" data-size="small" data-rawwidth="1080" data-rawheight="1038" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-001eea370bb4350424ae6be8c440c5be_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-001eea370bb4350424ae6be8c440c5be_b.jpg"><figcaption>图7.1 non-local means 滤波示意图：non-local顾名思义，将这个邻域扩展到全图。如上图p作为中心像素，q1，q2，q3对p的滤波都有贡献，实际上图像上任意一个点都有贡献。</figcaption></figure><p class="ztext-empty-paragraph"><br></p><figure data-size="small"><noscript><img src="https://pic4.zhimg.com/v2-1a5d798940278c7b8032c7f186173247_b.jpg" data-size="small" data-rawwidth="684" data-rawheight="726" class="origin_image zh-lightbox-thumb" width="684" data-original="https://pic4.zhimg.com/v2-1a5d798940278c7b8032c7f186173247_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-1a5d798940278c7b8032c7f186173247_hd.jpg" data-size="small" data-rawwidth="684" data-rawheight="726" class="origin_image zh-lightbox-thumb lazy" width="684" data-original="https://pic4.zhimg.com/v2-1a5d798940278c7b8032c7f186173247_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-1a5d798940278c7b8032c7f186173247_b.jpg"><figcaption>图7.2 None-local的实现方式</figcaption></figure><figure data-size="small"><noscript><img src="https://pic2.zhimg.com/v2-8ccda905605caf47dd3ef647b192a5e9_b.jpg" data-size="small" data-rawwidth="710" data-rawheight="326" class="origin_image zh-lightbox-thumb" width="710" data-original="https://pic2.zhimg.com/v2-8ccda905605caf47dd3ef647b192a5e9_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-8ccda905605caf47dd3ef647b192a5e9_hd.jpg" data-size="small" data-rawwidth="710" data-rawheight="326" class="origin_image zh-lightbox-thumb lazy" width="710" data-original="https://pic2.zhimg.com/v2-8ccda905605caf47dd3ef647b192a5e9_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-8ccda905605caf47dd3ef647b192a5e9_b.jpg"><figcaption>图7.3 None-local公式</figcaption></figure><p>Non-Local Networks 代码（pytorch）：</p><div class="highlight"><pre><code class="language-text">self.g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1, stride=1, padding=0)<font></font>
self.theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1, stride=1, padding=0)<font></font>
self.phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1, stride=1, padding=0)<font></font>
self.W = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels, kernel_size=1, stride=1, padding=0)<font></font>
<font></font>
<font></font>
g_x = self.g(x).view(batch_size, self.inter_channels, -1).permute(0, 2, 1)<font></font>
theta_x = self.theta(x).view(batch_size, self.inter_channels, -1).permute(0, 2, 1)<font></font>
phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)<font></font>
f = torch.matmul(theta_x, phi_x)<font></font>
f_div_C = F.softmax(f, dim=-1)<font></font>
y = torch.matmul(f_div_C, g_x).permute(0, 2, 1).contiguous()<font></font>
y = y.view(batch_size, self.inter_channels, *x.size()[2:])<font></font>
W_y = self.W(y)<font></font>
z = W_y + x</code></pre></div><figure data-size="small"><noscript><img src="https://pic4.zhimg.com/v2-d437f2b458e12cd0074b80e240a8c83f_b.jpg" data-size="small" data-rawwidth="764" data-rawheight="630" class="origin_image zh-lightbox-thumb" width="764" data-original="https://pic4.zhimg.com/v2-d437f2b458e12cd0074b80e240a8c83f_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-d437f2b458e12cd0074b80e240a8c83f_hd.jpg" data-size="small" data-rawwidth="764" data-rawheight="630" class="origin_image zh-lightbox-thumb lazy" width="764" data-original="https://pic4.zhimg.com/v2-d437f2b458e12cd0074b80e240a8c83f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-d437f2b458e12cd0074b80e240a8c83f_b.jpg"><figcaption>图7.4 Non-local 网络结构</figcaption></figure><p>特点：</p><ol><li>对于视频分类，non-local会好于相应的一般网络，毕竟没有大的感受野未必能很鲁棒的捕捉一个动作到底是跳高还是跳水。</li><li>依据作者们的结论，在网络浅层效果会更好，毕竟随着网络深度增加，传统网络感受野也会增加了，Non-local的效果也就不再明显。</li></ol><h2>8 Deformable Convolutional Networks</h2><p>同样的物体在图像中可能呈现出不同的大小、姿态、视角变化甚至非刚体形变，如何适应这些复杂的几何形变是物体识别的主要难点。而Deformable Conv模型尝试着解决这类问题。</p><blockquote>首次在卷积神经网络（convolutional neutral networks，CNN）中引入了学习空间几何形变的能力，得到可变形卷积网络（deformable convolutional networks），从而更好地解决了具有空间形变的图像识别任务。研究员们通过大量的实验结果验证了该方法在复杂的计算机视觉任务（如目标检测和语义分割）上的有效性，首次表明在深度卷积神经网络（deep CNN）中学习空间上密集的几何形变是可行的。<br>作者：微软亚洲研究院<br>链接：<a href="https://www.zhihu.com/question/57493889/answer/184578752" class="internal" data-za-detail-view-id="1043"><span class="invisible">https://www.</span><span class="visible">zhihu.com/question/5749</span><span class="invisible">3889/answer/184578752</span><span class="ellipsis"></span></a></blockquote><p>当前深度模型对物体的几何形变适应能力几乎还是来自于数据本身的多样性，模型内部并不具有适应几何形变的机制。作者认为造成这样的问题是卷积操作本身就是固定的几何结构。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-9d28f60a0566871bff39f146d88d946e_b.jpg" data-size="normal" class="content_image"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-9d28f60a0566871bff39f146d88d946e_hd.jpg" data-size="normal" class="content_image lazy" data-actualsrc="https://pic3.zhimg.com/v2-9d28f60a0566871bff39f146d88d946e_b.jpg"><figcaption>图7.5 展示了卷积核大小为 3x3 的正常卷积和可变形卷积的采样方式，(a) 所示的正常卷积规律的采样 9 个点（绿点），(b)(c)(d) 为可变形卷积，在正常的采样坐标上加上一个位移量（蓝色箭头），其中(c)(d) 作为 (b) 的特殊情况，展示了可变形卷积可以作为尺度变换，比例变换和旋转变换的特殊情况作</figcaption></figure><figure data-size="small"><noscript><img src="https://pic2.zhimg.com/v2-1d2996b769d919a2487f7b160bb750b5_b.jpg" data-size="small" data-rawwidth="656" data-rawheight="356" class="origin_image zh-lightbox-thumb" width="656" data-original="https://pic2.zhimg.com/v2-1d2996b769d919a2487f7b160bb750b5_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-1d2996b769d919a2487f7b160bb750b5_hd.jpg" data-size="small" data-rawwidth="656" data-rawheight="356" class="origin_image zh-lightbox-thumb lazy" width="656" data-original="https://pic2.zhimg.com/v2-1d2996b769d919a2487f7b160bb750b5_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-1d2996b769d919a2487f7b160bb750b5_b.jpg"><figcaption>图7.6 示例图</figcaption></figure><p class="ztext-empty-paragraph"><br></p><p class="ztext-empty-paragraph"><br></p><figure data-size="small"><noscript><img src="https://pic4.zhimg.com/v2-6274ab76f6a644ecf5bed200ceea2a5b_b.jpg" data-caption="" data-size="small" data-rawwidth="628" data-rawheight="464" class="origin_image zh-lightbox-thumb" width="628" data-original="https://pic4.zhimg.com/v2-6274ab76f6a644ecf5bed200ceea2a5b_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-6274ab76f6a644ecf5bed200ceea2a5b_hd.jpg" data-caption="" data-size="small" data-rawwidth="628" data-rawheight="464" class="origin_image zh-lightbox-thumb lazy" width="628" data-original="https://pic4.zhimg.com/v2-6274ab76f6a644ecf5bed200ceea2a5b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-6274ab76f6a644ecf5bed200ceea2a5b_b.jpg"></figure><figure data-size="small"><noscript><img src="https://pic3.zhimg.com/v2-b62eceececd70d1272642365e707c802_b.jpg" data-caption="" data-size="small" data-rawwidth="666" data-rawheight="464" class="origin_image zh-lightbox-thumb" width="666" data-original="https://pic3.zhimg.com/v2-b62eceececd70d1272642365e707c802_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-b62eceececd70d1272642365e707c802_hd.jpg" data-caption="" data-size="small" data-rawwidth="666" data-rawheight="464" class="origin_image zh-lightbox-thumb lazy" width="666" data-original="https://pic3.zhimg.com/v2-b62eceececd70d1272642365e707c802_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-b62eceececd70d1272642365e707c802_b.jpg"></figure><h2>9 Dilated Convolutional Networks</h2><p>Dilated Convolution 被中文翻译为“空洞卷积”或“膨胀卷积”，我更倾向于称之为“膨胀卷积”。该模型最早由<b>Fisher Yu</b>在2016年ICLR上发表的论文《Multi-Scale Context Aggregation by Dilation Convolutions》中提出。该模型最早应用于图像分割，因为传统CNN模型需要通过pooling层来缩小图像尺寸，并扩大下一层的感受野，即进行下采样（down sampling）；这一过程肯定会有信息丢失。因为图像分割是pixel-wise的，且在图像预测时还需要进行上采样（up sampling）操作，丢失的信息在上采样过程中也很难再找回。</p><p>为了解决上述问题，<b>Fisher Yu</b>提出了Dilated Convolution方法，通过Dilated Convolution来替代pooling层进行下采样操作，不仅扩大了感受野，也不会丢失信息。</p><p>下面看一下dilated conv原始论文中的示意图：</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-3c9df966ee79c38dd24b016856a2a328_b.jpg" data-caption="" data-size="normal" data-rawwidth="1754" data-rawheight="914" class="origin_image zh-lightbox-thumb" width="1754" data-original="https://pic1.zhimg.com/v2-3c9df966ee79c38dd24b016856a2a328_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-3c9df966ee79c38dd24b016856a2a328_hd.jpg" data-caption="" data-size="normal" data-rawwidth="1754" data-rawheight="914" class="origin_image zh-lightbox-thumb lazy" width="1754" data-original="https://pic1.zhimg.com/v2-3c9df966ee79c38dd24b016856a2a328_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-3c9df966ee79c38dd24b016856a2a328_b.jpg"></figure><p>(a)图对应3x3的1-dilated conv，和普通的卷积操作一样，(b)图对应3x3的2-dilated conv，实际的卷积kernel size还是3x3，但是空洞为1，也就是对于一个7x7的图像patch，只有9个红色的点和3x3的kernel发生卷积操作，其余的点略过。也可以理解为kernel的size为7x7，但是只有图中的9个点的权重不为0，其余都为0。 可以看到虽然kernel size只有3x3，但是这个卷积的感受野已经增大到了7x7（如果考虑到这个2-dilated conv的前一层是一个1-dilated conv的话，那么每个红点就是1-dilated的卷积输出，所以感受野为3x3，所以1-dilated和2-dilated合起来就能达到7x7的conv）,(c)图是4-dilated conv操作，同理跟在两个1-dilated和2-dilated conv的后面，能达到15x15的感受野。对比传统的conv操作，3层3x3的卷积加起来，stride为1的话，只能达到(kernel-1)*layer+1=7的感受野，也就是和层数layer成线性关系，而dilated conv的感受野是指数级的增长。</p><p><b>10 SENET</b></p><p>SENET在ImageNet 2017中的Image Classification夺得冠军。并在CVPR 2017中发表论文《Squeeze-and-excitation networks》。</p><p>作者大概总结了前人对CNN模型的改进：卷积核作为卷积神经网络的核心，通常被看做是在局部感受野上，将空间上（spatial）的信息和特征维度上（channel-wise）的信息进行聚合的信息聚合体。卷积神经网络由一系列卷积层、非线性层和下采样层构成，这样它们能够从全局感受野上去捕获图像的特征来进行图像的描述。</p><p>近很多工作被提出来从空间维度层面来提升网络的性能，如Inception结构中嵌入了多尺度信息，聚合多种不同感受野上的特征来获得性能增益；还如Non-local，deformable conv，dilated conv等都是在空间层面进行改进。</p><p>本文提到的SENet另辟蹊径，尝试着从channel特征中寻找优化点。作者认为在每层卷积中输出的每个channel，其信息重要性是不同的，我们需要为每个channel的feature map设置一个权重，来重新量化每个channel的特征信息。作者的设计如下图所示：</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-1bd3675aed6d5417bfb358d08fc9e8f4_b.jpg" data-caption="" data-size="normal" data-rawwidth="2144" data-rawheight="532" class="origin_image zh-lightbox-thumb" width="2144" data-original="https://pic1.zhimg.com/v2-1bd3675aed6d5417bfb358d08fc9e8f4_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-1bd3675aed6d5417bfb358d08fc9e8f4_hd.jpg" data-caption="" data-size="normal" data-rawwidth="2144" data-rawheight="532" class="origin_image zh-lightbox-thumb lazy" width="2144" data-original="https://pic1.zhimg.com/v2-1bd3675aed6d5417bfb358d08fc9e8f4_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-1bd3675aed6d5417bfb358d08fc9e8f4_b.jpg"></figure><p>图中Fsq为Squeeze操作，将每个二维的特征通道变成一个实数，这个实数某种程度上具有全局的感受野，并且输出的维度和输入的特征通道数相匹配。</p><p>图中Fex为Excitation操作，它是一个类似于循环神经网络中门的机制。通过参数 来为每个特征通道生成权重，其中参数 被学习用来显式地建模特征通道间的相关性。</p><p>图中Fscale是一个Reweight操作。完成了每个channel的特征图权重计算。</p><p>SE作为一个模块，可以跟其他CNN模型进行组合使用，下图是分别于Inception和ResNet进行组合</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-02554d51a722bb6bfea8f2f672a46cea_b.jpg" data-caption="" data-size="normal" data-rawwidth="2242" data-rawheight="866" class="origin_image zh-lightbox-thumb" width="2242" data-original="https://pic3.zhimg.com/v2-02554d51a722bb6bfea8f2f672a46cea_r.jpg"/></noscript><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-02554d51a722bb6bfea8f2f672a46cea_hd.jpg" data-caption="" data-size="normal" data-rawwidth="2242" data-rawheight="866" class="origin_image zh-lightbox-thumb lazy" width="2242" data-original="https://pic3.zhimg.com/v2-02554d51a722bb6bfea8f2f672a46cea_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-02554d51a722bb6bfea8f2f672a46cea_b.jpg"></figure><p class="ztext-empty-paragraph"><br></p><p class="ztext-empty-paragraph"><br></p><p>参考文献：</p><a target="_blank" href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/IMkvod2Lj2VOIWbFtAirzA" data-draft-node="block" data-draft-type="link-card" data-image="https://pic1.zhimg.com/v2-037f7f002fec0319694f70591f204804_180x120.jpg" data-image-width="832" data-image-height="467" class="LinkCard LinkCard--hasImage" data-za-detail-view-id="172"><span class="LinkCard-backdrop" style="background-image:url(https://pic1.zhimg.com/v2-037f7f002fec0319694f70591f204804_180x120.jpg)"></span><span class="LinkCard-content"><span class="LinkCard-text"><span class="LinkCard-title" data-text="true">想入门设计卷积神经网络？这是一份综合设计指南</span><span class="LinkCard-meta"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--InsertLink" fill="currentColor" viewBox="0 0 24 24" width="17" height="17"><path d="M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z" fill-rule="evenodd"></path></svg></span>mp.weixin.qq.com</span></span><span class="LinkCard-imageCell"><img class="LinkCard-image LinkCard-image--horizontal" alt="圖標" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-037f7f002fec0319694f70591f204804_180x120.jpg"></span></span></a><a target="_blank" href="https://zhuanlan.zhihu.com/p/45189981" data-draft-node="block" data-draft-type="link-card" data-image="https://pic1.zhimg.com/v2-6b8b7a6a91978129edac137035860c24_180x120.jpg" data-image-width="720" data-image-height="284" class="LinkCard LinkCard--hasImage" data-za-detail-view-id="172"><span class="LinkCard-backdrop" style="background-image:url(https://pic1.zhimg.com/v2-6b8b7a6a91978129edac137035860c24_180x120.jpg)"></span><span class="LinkCard-content"><span class="LinkCard-text"><span class="LinkCard-title" data-text="true">深度智能：InceptionNet 从v1到v4的演变</span><span class="LinkCard-meta"><span style="display:inline-flex;align-items:center">​<svg class="Zi Zi--InsertLink" fill="currentColor" viewBox="0 0 24 24" width="17" height="17"><path d="M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z" fill-rule="evenodd"></path></svg></span>zhuanlan.zhihu.com</span></span><span class="LinkCard-imageCell"><img class="LinkCard-image LinkCard-image--horizontal" alt="圖標" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-6b8b7a6a91978129edac137035860c24_180x120.jpg"></span></span></a><a target="_blank" href="https://www.zhihu.com/question/312556066" data-draft-node="block" data-draft-type="link-card" data-image="https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg" class="LinkCard LinkCard--hasImage" data-za-detail-view-id="172"><span class="LinkCard-backdrop" style="background-image:url(https://zhstatic.zhihu.com/assets/zhihu/editor/zhihu-card-default.svg)"></span><span class="LinkCard-content"><span class="LinkCard-text"><span class="LinkCard-title" data-text="true"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">卷積神經網絡（CNN）的結構設計都有哪些思想？</font></font></span><font style="vertical-align: inherit;"><span class="LinkCard-meta"><font style="vertical-align: inherit;">​www.zhihu.com</font></span></font><span class="LinkCard-meta"><span style="display:inline-flex;align-items:center"><font style="vertical-align: inherit;"></font><svg class="Zi Zi--InsertLink" fill="currentColor" viewBox="0 0 24 24" width="17" height="17"><path d="M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"></font></span></span><span class="LinkCard-imageCell"><img class="LinkCard-image LinkCard-image--square" alt="圖標" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/zhihu-card-default.svg"></span></span></a><font style="vertical-align: inherit;"><a target="_blank" href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26scene%3D21%23wechat_redirect" data-draft-node="block" data-draft-type="link-card" class="LinkCard LinkCard--noImage" data-za-detail-view-id="172"><span class="LinkCard-content"><span class="LinkCard-text"><span class="LinkCard-meta"><font style="vertical-align: inherit;"> https://mp.weixin.qq.com/s?__biz=MzA3NDIyMjM1NA==&amp;mid=2649029645&amp;idx=1&amp;sn=75b494ec181fee3e8756bb0fa119e7ce&amp;chksm=87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07&amp;scene=21#wechat_redirect​mp.weixin.qq.com</font></span></span></span></a></font><a target="_blank" href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26scene%3D21%23wechat_redirect" data-draft-node="block" data-draft-type="link-card" class="LinkCard LinkCard--noImage" data-za-detail-view-id="172"><span class="LinkCard-content"><span class="LinkCard-text"><span class="LinkCard-title" data-text="true"><font style="vertical-align: inherit;"></font></span><span class="LinkCard-meta"><span style="display:inline-flex;align-items:center"><font style="vertical-align: inherit;"></font><svg class="Zi Zi--InsertLink" fill="currentColor" viewBox="0 0 24 24" width="17" height="17"><path d="M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"></font></span></span><span class="LinkCard-imageCell"><div class="LinkCard-image LinkCard-image--default"><svg class="Zi Zi--Browser" fill="currentColor" viewBox="0 0 24 24" width="32" height="32"><path d="M11.991 3C7.023 3 3 7.032 3 12s4.023 9 8.991 9C16.968 21 21 16.968 21 12s-4.032-9-9.009-9zm6.237 5.4h-2.655a14.084 14.084 0 0 0-1.242-3.204A7.227 7.227 0 0 1 18.228 8.4zM12 4.836A12.678 12.678 0 0 1 13.719 8.4h-3.438A12.678 12.678 0 0 1 12 4.836zM5.034 13.8A7.418 7.418 0 0 1 4.8 12c0-.621.09-1.224.234-1.8h3.042A14.864 14.864 0 0 0 7.95 12c0 .612.054 1.206.126 1.8H5.034zm.738 1.8h2.655a14.084 14.084 0 0 0 1.242 3.204A7.188 7.188 0 0 1 5.772 15.6zm2.655-7.2H5.772a7.188 7.188 0 0 1 3.897-3.204c-.54.999-.954 2.079-1.242 3.204zM12 19.164a12.678 12.678 0 0 1-1.719-3.564h3.438A12.678 12.678 0 0 1 12 19.164zm2.106-5.364H9.894A13.242 13.242 0 0 1 9.75 12c0-.612.063-1.215.144-1.8h4.212c.081.585.144 1.188.144 1.8 0 .612-.063 1.206-.144 1.8zm.225 5.004c.54-.999.954-2.079 1.242-3.204h2.655a7.227 7.227 0 0 1-3.897 3.204zm1.593-5.004c.072-.594.126-1.188.126-1.8 0-.612-.054-1.206-.126-1.8h3.042c.144.576.234 1.179.234 1.8s-.09 1.224-.234 1.8h-3.042z"></path></svg></div></span></span></a><a target="_blank" href="https://www.zhihu.com/question/57493889/answer/184578752" data-draft-node="block" data-draft-type="link-card" data-image="https://pic3.zhimg.com/v2-9d28f60a0566871bff39f146d88d946e_180x120.jpg" data-image-width="640" data-image-height="229" class="LinkCard LinkCard--hasImage" data-za-detail-view-id="172"><span class="LinkCard-backdrop" style="background-image:url(https://pic3.zhimg.com/v2-9d28f60a0566871bff39f146d88d946e_180x120.jpg)"></span><span class="LinkCard-content"><span class="LinkCard-text"><span class="LinkCard-title" data-text="true"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">如何評價MSRA最新的Deformable Convolutional Networks？</font></font></span><font style="vertical-align: inherit;"><span class="LinkCard-meta"><font style="vertical-align: inherit;">​www.zhihu.com</font></span></font><span class="LinkCard-meta"><span style="display:inline-flex;align-items:center"><font style="vertical-align: inherit;"></font><svg class="Zi Zi--InsertLink" fill="currentColor" viewBox="0 0 24 24" width="17" height="17"><path d="M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"></font></span></span><span class="LinkCard-imageCell"><img class="LinkCard-image LinkCard-image--horizontal" alt="圖標" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-9d28f60a0566871bff39f146d88d946e_180x120.jpg"></span></span></a><a target="_blank" href="https://www.zhihu.com/question/54149221/answer/192025860" data-draft-node="block" data-draft-type="link-card" data-image="https://pic4.zhimg.com/v2-036913d7176af92daffcd60698751397_180x120.jpg" data-image-width="869" data-image-height="720" class="LinkCard LinkCard--hasImage" data-za-detail-view-id="172"><span class="LinkCard-backdrop" style="background-image:url(https://pic4.zhimg.com/v2-036913d7176af92daffcd60698751397_180x120.jpg)"></span><span class="LinkCard-content"><span class="LinkCard-text"><span class="LinkCard-title" data-text="true"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">如何理解空洞卷積（dilated convolution）？</font></font></span><font style="vertical-align: inherit;"><span class="LinkCard-meta"><font style="vertical-align: inherit;">​www.zhihu.com</font></span></font><span class="LinkCard-meta"><span style="display:inline-flex;align-items:center"><font style="vertical-align: inherit;"></font><svg class="Zi Zi--InsertLink" fill="currentColor" viewBox="0 0 24 24" width="17" height="17"><path d="M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"></font></span></span><span class="LinkCard-imageCell"><img class="LinkCard-image LinkCard-image--horizontal" alt="圖標" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-036913d7176af92daffcd60698751397_180x120.jpg"></span></span></a><p><br>                                         <a href="https://www.zhihu.com/question/63460684/answer/300021819" class="internal" data-za-detail-view-id="1043"><span class="invisible"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https://www. </font></font></span><span class="visible"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">zhihu.com/question/6346 </font></font></span><span class="invisible"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0684/answer/300021819</font></font></span><span class="ellipsis"></span></a></p></div></div><div class="ContentItem-time"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">編輯於2019-06-15</font></font></div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic" data-za-detail-view-path-module="TopicItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Topic&quot;,&quot;token&quot;:&quot;20043586&quot;}}}"><span class="Tag-content"><a class="TopicLink" href="https://www.zhihu.com/topic/20043586" target="_blank"><div class="Popover"><div id="Popover4-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover4-content"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">卷積神經網絡（CNN）</font></font></div></div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-fixed is-bottom" style="width: 690px; bottom: 0px; left: 606.5px;"><div class="ContentItem-actions" data-za-detail-view-path-module="BottomBar" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;id&quot;:&quot;66215918&quot;}}}"><span><button aria-label="贊同318" type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M2 18.242c0-.326.088-.532.237-.896l7.98-13.203C10.572 3.57 11.086 3 12 3c.915 0 1.429.571 1.784 1.143l7.98 13.203c.15.364.236.57.236.896 0 1.386-.875 1.9-1.955 1.9H3.955c-1.08 0-1.955-.517-1.955-1.9z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">贊同318</font></font></button><button aria-label="反對" type="button" class="Button VoteButton VoteButton--down"><span style="display:inline-flex;align-items:center"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--TriangleDown" fill="currentColor" viewBox="0 0 24 24" width="10" height="10"><path d="M20.044 3H3.956C2.876 3 2 3.517 2 4.9c0 .326.087.533.236.896L10.216 19c.355.571.87 1.143 1.784 1.143s1.429-.572 1.784-1.143l7.98-13.204c.149-.363.236-.57.236-.896 0-1.386-.876-1.9-1.956-1.9z" fill-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​8</font></font><svg class="Zi Zi--Comment Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M10.241 19.313a.97.97 0 0 0-.77.2 7.908 7.908 0 0 1-3.772 1.482.409.409 0 0 1-.38-.637 5.825 5.825 0 0 0 1.11-2.237.605.605 0 0 0-.227-.59A7.935 7.935 0 0 1 3 11.25C3 6.7 7.03 3 12 3s9 3.7 9 8.25-4.373 9.108-10.759 8.063z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">條評論</font></font></button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="Popover5-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover5-content"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Share Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M2.931 7.89c-1.067.24-1.275 1.669-.318 2.207l5.277 2.908 8.168-4.776c.25-.127.477.198.273.39L9.05 14.66l.927 5.953c.18 1.084 1.593 1.376 2.182.456l9.644-15.242c.584-.892-.212-2.029-1.234-1.796L2.93 7.89z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">分享</font></font></button></div></div><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Star Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5.515 19.64l.918-5.355-3.89-3.792c-.926-.902-.639-1.784.64-1.97L8.56 7.74l2.404-4.871c.572-1.16 1.5-1.16 2.072 0L15.44 7.74l5.377.782c1.28.186 1.566 1.068.64 1.97l-3.89 3.793.918 5.354c.219 1.274-.532 1.82-1.676 1.218L12 18.33l-4.808 2.528c-1.145.602-1.896.056-1.677-1.218z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">收藏</font></font></button><div class="Post-ActionMenuButton"><div class="Popover"><div id="Popover6-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover6-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly"><span style="display:inline-flex;align-items:center"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Dots Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M5 14a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4zm7 0a2 2 0 1 1 0-4 2 2 0 0 1 0 4z" fill-rule="evenodd"></path></svg></span></button></div></div></div></div><div data-za-detail-view-path-module="LeftTabBar" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;id&quot;:&quot;66215918&quot;}}}"></div></div><div class="Sticky--holder" style="position: static; top: auto; right: auto; bottom: 0px; left: 0px; display: block; float: none; margin: 0px 0px 10px; height: 54px;"></div></div></article><div class="Post-Sub Post-NormalSub"><div class="PostIndex-Contributions" data-za-detail-view-path-module="ColumnList" data-za-detail-view-path-module_name="文章被以下专栏收录" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:null}}"><h3 class="BlockTitle"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">文章被以下專欄收錄</font></font></h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="https://zhuanlan.zhihu.com/c_1123912990784966656"><div class="Popover"><div id="Popover7-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover7-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/4b70deef7_xs.jpg" srcset="https://pic2.zhimg.com/4b70deef7_l.jpg 2x" alt="計算機視覺學習筆記"></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><a class="ColumnLink ColumnItem-Title" href="https://zhuanlan.zhihu.com/c_1123912990784966656"><div class="Popover"><div id="Popover8-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover8-content"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">計算機視覺學習筆記</font></font></div></div></a></h2></div><div class="ContentItem-extra"><a href="https://zhuanlan.zhihu.com/c_1123912990784966656" type="button" class="Button"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">進入專欄</font></font></a></div></div></div></ul></div><div class="Recommendations-Main" style="width: 1903px;"><h3 class="BlockTitle Recommendations-BlockTitle"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">推薦閱讀</font></font></h3><ul class="Recommendations-List"><button class="PagingButton PagingButton-Previous" disabled=""><svg class="Zi Zi--ArrowLeft" fill="#d3d3d3" viewBox="0 0 24 24" width="40" height="40"><path d="M14.782 16.78a.737.737 0 0 1-1.052 0L9.218 12.53a.758.758 0 0 1 0-1.063L13.73 7.22a.737.737 0 0 1 1.052 0c.29.294.29.77.001 1.063L11 12l3.782 3.716c.29.294.29.77 0 1.063z" fill-rule="evenodd"></path></svg></button><a href="https://zhuanlan.zhihu.com/p/56194480" class="PostItem"><div><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-1644259c2912cfa5a9faf994147bbf3a_250x0.jpg" srcset="https://pic2.zhimg.com/v2-1644259c2912cfa5a9faf994147bbf3a_qhd.jpg 2x" class="PostItem-TitleImage" alt="AAAI 2019 論文解讀：卷積神經網絡繼續進步"><h1 class="PostItem-Title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AAAI 2019 論文解讀：卷積神經網絡繼續進步</font></font></h1><div class="PostItem-Footer"><span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">機器之心</font></font></span><span class="PostItem-FooterTitle"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">發表於機器之心</font></font></span></div></div></a><a href="https://zhuanlan.zhihu.com/p/32273805" class="PostItem"><div><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-ac4e433c03e247f19ab24c4f301f0b39_250x0.jpg" srcset="https://pic1.zhimg.com/v2-ac4e433c03e247f19ab24c4f301f0b39_qhd.jpg 2x" class="PostItem-TitleImage" alt="三分鐘了解卷積神經網絡(CNN)"><h1 class="PostItem-Title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">三分鐘了解卷積神經網絡(CNN)</font></font></h1><div class="PostItem-Footer"><span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Miruk... </font></font></span><span class="PostItem-FooterTitle"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">發表於極簡深度學...</font></font></span></div></div></a><a href="https://zhuanlan.zhihu.com/p/49816977" class="PostItem"><div><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-b08615d9759bdb3c7a77424d27142890_250x0.jpg" srcset="https://pic1.zhimg.com/v2-b08615d9759bdb3c7a77424d27142890_qhd.jpg 2x" class="PostItem-TitleImage" alt="CNN經典模型—Alexnet"><h1 class="PostItem-Title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CNN經典模型—Alexnet</font></font></h1><div class="PostItem-Footer"><span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">人在旅途</font></font></span><span class="PostItem-FooterTitle"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">發表於深度學習面...</font></font></span></div></div></a><a href="https://zhuanlan.zhihu.com/p/67834114" class="PostItem"><div><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-cd04fea5dd2039d7ed31f1b60af54132_250x0.jpg" srcset="https://pic2.zhimg.com/v2-cd04fea5dd2039d7ed31f1b60af54132_qhd.jpg 2x" class="PostItem-TitleImage" alt="EfficientNet-可能是迄今為止最好的CNN網絡"><h1 class="PostItem-Title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">EfficientNet-可能是迄今為止最好的CNN網絡</font></font></h1><div class="PostItem-Footer"><span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">清華阿羅</font></font></span><span class="PostItem-FooterTitle"></span></div></div></a><button class="PagingButton PagingButton-Next"><svg class="Zi Zi--ArrowRight" fill="#d3d3d3" viewBox="0 0 24 24" width="40" height="40"><path d="M9.218 16.78a.737.737 0 0 0 1.052 0l4.512-4.249a.758.758 0 0 0 0-1.063L10.27 7.22a.737.737 0 0 0-1.052 0 .759.759 0 0 0-.001 1.063L13 12l-3.782 3.716a.758.758 0 0 0 0 1.063z" fill-rule="evenodd"></path></svg></button></ul></div><div class="Comments-container" data-za-detail-view-path-module="CommentList" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:null}}"><div class="CommentsV2 CommentsV2--withEditor CommentsV2-withPagination"><div class="Topbar CommentTopbar"><div class="Topbar-title"><h2 class="CommentTopbar-title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">8 條評論</font></font></h2></div><div class="Topbar-options"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Switch Button-zi" fill="currentColor" viewBox="0 0 24 24" width="1.2em" height="1.2em"><path d="M13.004 7V4.232c0-.405.35-.733.781-.733.183 0 .36.06.501.17l6.437 5.033c.331.26.376.722.1 1.033a.803.803 0 0 1-.601.264H2.75a.75.75 0 0 1-.75-.75V7.75A.75.75 0 0 1 2.75 7h10.254zm-1.997 9.999v2.768c0 .405-.35.733-.782.733a.814.814 0 0 1-.5-.17l-6.437-5.034a.702.702 0 0 1-.1-1.032.803.803 0 0 1 .6-.264H21.25a.75.75 0 0 1 .75.75v1.499a.75.75 0 0 1-.75.75H11.007z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">切換為時間排序</font></font></button></div></div><div class="CommentsV2-footer CommentEditorV2--normal"><div class="CommentEditorV2-inputWrap"><div class="CommentEditorV2-input Input-wrapper Input-wrapper--spread Input-wrapper--large Input-wrapper--noPadding"><div class="Input Editable"><div class="Dropzone RichText RichText--editable RichText--clearBoth ztext" style="min-height: 198px;"><div class="DraftEditor-root"><div class="public-DraftEditorPlaceholder-root"><div class="public-DraftEditorPlaceholder-inner" id="placeholder-fskd3" style="white-space: pre-wrap;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">寫下你的評論...</font></font></div></div><div class="DraftEditor-editorContainer"><div aria-describedby="placeholder-fskd3" class="notranslate public-DraftEditor-content" contenteditable="true" role="textbox" spellcheck="true" tabindex="0" style="outline: none; user-select: text; white-space: pre-wrap; overflow-wrap: break-word;"><div data-contents="true"><div class="Editable-unstyled" data-block="true" data-editor="fskd3" data-offset-key="ak47u-0-0"><div data-offset-key="ak47u-0-0" class="public-DraftStyleDefault-block public-DraftStyleDefault-ltr"><span data-offset-key="ak47u-0-0"><br data-text="true"></span></div></div></div></div></div></div></div><input multiple="" type="file" accept="image/jpg,image/jpeg,image/png,image/gif" style="display: none;"><div></div></div></div><div class="CommentEditorV2-inputUpload"><div class="CommentEditorV2-popoverWrap"><div class="Popover CommentEditorV2-inputUpLoad-Icon"><button aria-label="插入表情" data-tooltip="插入表情" data-tooltip-position="bottom" data-tooltip-will-hide-on-click="true" id="Popover9-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover9-content" type="button" class="Button Editable-control Button--plain"><svg class="Zi Zi--Emotion" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M7.523 13.5h8.954c-.228 2.47-2.145 4-4.477 4-2.332 0-4.25-1.53-4.477-4zM12 21a9 9 0 1 1 0-18 9 9 0 0 1 0 18zm0-1.5a7.5 7.5 0 1 0 0-15 7.5 7.5 0 0 0 0 15zm-3-8a1.5 1.5 0 1 1 0-3 1.5 1.5 0 0 1 0 3zm6 0a1.5 1.5 0 1 1 0-3 1.5 1.5 0 0 1 0 3z"></path></svg></button></div></div></div></div><button disabled="" type="button" class="Button CommentEditorV2-singleButton Button--primary Button--blue"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">發布</font></font></button></div><div><div class="CommentListV2"><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><img class="Avatar UserLink-avatar" width="24" height="24" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/da8e974dc_s.jpg" srcset="https://pic4.zhimg.com/da8e974dc_xs.jpg 2x" alt="知乎用戶"></span><span class="UserLink"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">知乎用戶</font></font></span><span class="CommentItemV2-time"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1個月前</font></font></span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">寫的很好，消除零評論！</font></font></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">贊</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">回复</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">踩</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">舉報</font></font></button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover20-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover20-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/lu-peng-jie"><img class="Avatar UserLink-avatar" width="24" height="24" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/ca53708bf_s.jpg" srcset="https://pic3.zhimg.com/ca53708bf_xs.jpg 2x" alt="Benjaminlpj"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/lu-peng-jie"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Benjaminlpj</font></font></a></span><span class="CommentItemV2-time"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 1個月前</font></font></span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">感謝！</font></font></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">贊</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">回复</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">踩</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">舉報</font></font></button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover21-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover21-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/lorica"><img class="Avatar UserLink-avatar" width="24" height="24" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/da8e974dc_s.jpg" srcset="https://pic4.zhimg.com/da8e974dc_xs.jpg 2x" alt="lorica"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/lorica"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">lorica</font></font></a></span><span class="CommentItemV2-time"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 25天前</font></font></span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">牛逼，思路真的很清晰</font></font></p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">贊</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">回复</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">踩</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">舉報</font></font></button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover22-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover22-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/huang-wei-ran-88"><img class="Avatar UserLink-avatar" width="24" height="24" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/1ee394d00bb095ec443edd31b58303fa_s.jpg" srcset="https://pic2.zhimg.com/1ee394d00bb095ec443edd31b58303fa_xs.jpg 2x" alt="Gimosolv"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/huang-wei-ran-88"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Gimosolv</font></font></a></span><span class="CommentItemV2-time"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 21天前</font></font></span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">不是我說啊，2019年6月了，你拿出一個python2.7 pytorch 0.3會不會有點不合時宜</font></font></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"></font><svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​8</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">回复</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">踩</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">舉報</font></font></button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover23-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover23-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/teddyzhang001"><img class="Avatar UserLink-avatar" width="24" height="24" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-9007902f1194e74c61d7acf1439c0fac_s.jpg" srcset="https://pic3.zhimg.com/v2-9007902f1194e74c61d7acf1439c0fac_xs.jpg 2x" alt="TeddyZhang"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/teddyzhang001"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">TeddyZhang</font></font></a></span><span class="CommentItemV2-time"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 14天前</font></font></span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">9012年了，樓主還是更新下版本吧</font></font></p><div class="Richtext-content_img Richtext-content_img-square"><img class="comment_sticker" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-90359a720808ff45062287127cfa1039.gif" data-original="https://pic2.zhimg.com/v2-90359a720808ff45062287127cfa1039_r.gif" data-rawwidth="NaN"></div></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">贊</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">回复</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">踩</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">舉報</font></font></button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover24-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover24-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/mkp-85"><img class="Avatar UserLink-avatar" width="24" height="24" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/da8e974dc_s.jpg" srcset="https://pic4.zhimg.com/da8e974dc_xs.jpg 2x" alt="MKP"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/mkp-85"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MKP</font></font></a></span><span class="CommentItemV2-time"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 4天前</font></font></span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">🤔resnext怎麼樣呢</font></font></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">贊</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">回复</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">踩</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">舉報</font></font></button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><div class="Popover"><div id="Popover25-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover25-content"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/suan-fa-cai-ji"><img class="Avatar UserLink-avatar" width="24" height="24" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/v2-1248b9878e47240000c7e5a2def2ddfb_s.jpg" srcset="https://pic3.zhimg.com/v2-1248b9878e47240000c7e5a2def2ddfb_xs.jpg 2x" alt="發發"></a></div></div></span><span class="UserLink"><a class="UserLink-link" data-za-detail-view-element_name="User" target="_blank" href="https://www.zhihu.com/people/suan-fa-cai-ji"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">發發</font></font></a></span><span class="CommentItemV2-time"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 4天前</font></font></span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">百度的為毛不用padlepadle? 用啥pytorch呀.</font></font></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">贊</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">回复</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">踩</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">舉報</font></font></button></div></div></div></div></li></ul><ul class="NestComment"><li class="NestComment--rootCommentNoChild"><div class="CommentItemV2"><div><div class="CommentItemV2-meta"><span class="UserLink CommentItemV2-avatar"><img class="Avatar UserLink-avatar" width="24" height="24" src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/da8e974dc_s.jpg" srcset="https://pic4.zhimg.com/da8e974dc_xs.jpg 2x" alt="知乎用戶"></span><span class="UserLink"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">知乎用戶</font></font></span><span class="CommentItemV2-time"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3天前</font></font></span></div><div class="CommentItemV2-metaSibling"><div class="CommentRichText CommentItemV2-content"><div class="RichText ztext"><p><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">謝謝樓主！</font></font></p></div></div><div class="CommentItemV2-footer"><button type="button" class="Button CommentItemV2-likeBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">贊</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Reply" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M22.959 17.22c-1.686-3.552-5.128-8.062-11.636-8.65-.539-.053-1.376-.436-1.376-1.561V4.678c0-.521-.635-.915-1.116-.521L1.469 10.67a1.506 1.506 0 0 0-.1 2.08s6.99 6.818 7.443 7.114c.453.295 1.136.124 1.135-.501V17a1.525 1.525 0 0 1 1.532-1.466c1.186-.139 7.597-.077 10.33 2.396 0 0 .396.257.536.257.892 0 .614-.967.614-.967z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">回复</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Like" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="transform: rotate(180deg); margin-right: 5px;"><path d="M14.445 9h5.387s2.997.154 1.95 3.669c-.168.51-2.346 6.911-2.346 6.911s-.763 1.416-2.86 1.416H8.989c-1.498 0-2.005-.896-1.989-2v-7.998c0-.987.336-2.032 1.114-2.639 4.45-3.773 3.436-4.597 4.45-5.83.985-1.13 3.2-.5 3.037 2.362C15.201 7.397 14.445 9 14.445 9zM3 9h2a1 1 0 0 1 1 1v10a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V10a1 1 0 0 1 1-1z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">踩</font></font></button><button type="button" class="Button CommentItemV2-hoverBtn Button--plain"><span style="display: inline-flex; align-items: center;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">​</font></font><svg class="Zi Zi--Report" fill="currentColor" viewBox="0 0 24 24" width="16" height="16" style="margin-right: 5px;"><path d="M19.947 3.129c-.633.136-3.927.639-5.697.385-3.133-.45-4.776-2.54-9.949-.888-.997.413-1.277 1.038-1.277 2.019L3 20.808c0 .3.101.54.304.718a.97.97 0 0 0 .73.304c.275 0 .519-.102.73-.304.202-.179.304-.418.304-.718v-6.58c4.533-1.235 8.047.668 8.562.864 2.343.893 5.542.008 6.774-.657.397-.178.596-.474.596-.887V3.964c0-.599-.42-.972-1.053-.835z" fill-rule="evenodd"></path></svg></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">舉報</font></font></button></div></div></div></div></li></ul></div><span></span></div></div></div></div></div></main><div class="CornerButtons"><div class="CornerAnimayedFlex CornerAnimayedFlex--hidden"><button data-tooltip="回到顶部" data-tooltip-position="left" data-tooltip-will-hide-on-click="true" aria-label="回到頂部" type="button" class="Button CornerButton Button--plain"><svg class="Zi Zi--BackToTop" title="回到頂部" fill="currentColor" viewBox="0 0 24 24" width="24" height="24"><path d="M16.036 19.59a1 1 0 0 1-.997.995H9.032a.996.996 0 0 1-.997-.996v-7.005H5.03c-1.1 0-1.36-.633-.578-1.416L11.33 4.29a1.003 1.003 0 0 1 1.412 0l6.878 6.88c.782.78.523 1.415-.58 1.415h-3.004v7.005z"></path></svg></button></div></div></div></div><script id="js-clientConfig" type="text/json">{"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","zhuanlanHost":"zhuanlan.zhihu.com","apiHost":"api.zhihu.com"}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false}},"entities":{"users":{"liuyuemaicha":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002F0a900ad0d691e76a0ba1d5a5306698a1_{size}.jpg","uid":"73502124146688","userType":"people","isFollowing":false,"urlToken":"liuyuemaicha","id":"3ace18227686ca3672d6024be1b0d0f5","description":"","name":"KevinCK","isAdvertiser":false,"headline":"徘徊前进的男程，关注CV领域","gender":1,"url":"\u002Fpeople\u002F3ace18227686ca3672d6024be1b0d0f5","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002F0a900ad0d691e76a0ba1d5a5306698a1_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"百度 计算机视觉工程师"}],"exposedMedal":{"medalId":"972477022068568064","medalName":"备受瞩目","avatarUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-cb6e5c42f3c7428aa80cf44ff4868a67_r.png","miniAvatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e8f194e35bb3a8bd187a957e8764d587_is.png","description":"被 1000 个人关注"}}},"questions":{},"answers":{},"articles":{"66215918":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fpage_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=__MEMBERID__&idfa=__IDFA__&imei=__IMEI__&androidid= __ANDROIDID__"],"id":66215918,"title":"CNN系列模型发展简述（附github代码——已全部跑通）","type":"article","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F66215918","imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-faab9fd88ef1c02923dc9f4fda5b7a4d_b.jpg","titleImage":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-faab9fd88ef1c02923dc9f4fda5b7a4d_b.jpg","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-cd72743c06bd695b89cbf1faf12994cb_200x112.jpg\" data-caption=\"图1.1：LeNet-5网络结构\" data-size=\"normal\" data-rawwidth=\"700\" data-rawheight=\"193\" data-watermark=\"watermark\" data-original-src=\"v2-cd72743c06bd695b89cbf1faf12994cb\" data-watermark-src=\"v2-bd5a9c288d4d9e26be5674a0bfac3ba1\" data-private-watermark-src=\"\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-cd72743c06bd695b89cbf1faf12994cb_r.jpg\" class=\"origin_image inline-img zh-lightbox-thumb\"\u002F\u003E目录： 1 LeNet 2 AlexNet 3 VGG 4 GoogLeNet 5 ResNet 6 DenseNet 7 Non-Local Networks 8 Deformable Convolutional Networks 9 Dilated Convolutional Networks 10 SENETGITHUB(持续更新):\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fliuyuemaicha\u002Fcnn_model\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"v2-be7f59346f9400a5e76e0e4bca873897\" data-image-width=\"400\" data-image-height=\"400\" data-image-size=\"ipico\"\u003Eliuyuemaicha\u002Fcnn_model\u003C\u002Fa\u003Egithub代码依赖： python 2.7, Pytorch 0…","created":1558175449,"updated":1560590128,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002F0a900ad0d691e76a0ba1d5a5306698a1_{size}.jpg","uid":"73502124146688","userType":"people","isFollowing":false,"urlToken":"liuyuemaicha","id":"3ace18227686ca3672d6024be1b0d0f5","description":"","name":"KevinCK","isAdvertiser":false,"headline":"徘徊前进的男程，关注CV领域","gender":1,"url":"\u002Fpeople\u002F3ace18227686ca3672d6024be1b0d0f5","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002F0a900ad0d691e76a0ba1d5a5306698a1_l.jpg","isOrg":false,"type":"people","badge":[{"type":"identity","topics":[],"description":"百度 计算机视觉工程师"}],"exposedMedal":{"medalId":"972477022068568064","medalName":"备受瞩目","avatarUrl":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-cb6e5c42f3c7428aa80cf44ff4868a67_r.png","miniAvatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e8f194e35bb3a8bd187a957e8764d587_is.png","description":"被 1000 个人关注"}},"commentPermission":"all","state":"published","imageWidth":844,"imageHeight":593,"content":"\u003Cblockquote\u003E目录：\u003Cbr\u002F\u003E1 LeNet\u003Cbr\u002F\u003E2 AlexNet\u003Cbr\u002F\u003E3 VGG\u003Cbr\u002F\u003E4 GoogLeNet\u003Cbr\u002F\u003E5 ResNet\u003Cbr\u002F\u003E6 DenseNet\u003Cbr\u002F\u003E7 Non-Local Networks\u003Cbr\u002F\u003E8 Deformable Convolutional Networks\u003Cbr\u002F\u003E9 Dilated Convolutional Networks\u003Cbr\u002F\u003E10 SENET\u003C\u002Fblockquote\u003E\u003Ch2\u003EGITHUB(持续更新):\u003C\u002Fh2\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fgithub.com\u002Fliuyuemaicha\u002Fcnn_model\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-be7f59346f9400a5e76e0e4bca873897_ipico.jpg\" data-image-width=\"400\" data-image-height=\"400\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003Eliuyuemaicha\u002Fcnn_model\u003C\u002Fa\u003E\u003Ch2\u003Egithub代码依赖： python 2.7, Pytorch 0.3.1\u003C\u002Fh2\u003E\u003Ch2\u003E1 LeNet\u003C\u002Fh2\u003E\u003Cp\u003ELeNet虽然不是CNN的起点，但却是后来CNN兴起的标志模型。LeNet-5是1998年YannLeCun设计用于手写数字识别的模型。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-bd5a9c288d4d9e26be5674a0bfac3ba1_b.jpg\" data-size=\"normal\" data-rawwidth=\"700\" data-rawheight=\"193\" class=\"origin_image zh-lightbox-thumb\" width=\"700\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-bd5a9c288d4d9e26be5674a0bfac3ba1_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;700&#39; height=&#39;193&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"700\" data-rawheight=\"193\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"700\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-bd5a9c288d4d9e26be5674a0bfac3ba1_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-bd5a9c288d4d9e26be5674a0bfac3ba1_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图1.1：LeNet-5网络结构\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e5b242d3cccd26c8eb395d15081bc0e3_b.jpg\" data-size=\"normal\" data-rawwidth=\"416\" data-rawheight=\"362\" class=\"content_image\" width=\"416\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;416&#39; height=&#39;362&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"416\" data-rawheight=\"362\" class=\"content_image lazy\" width=\"416\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e5b242d3cccd26c8eb395d15081bc0e3_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图1.2：LeNet-5网络结构\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E在当年神经网络还是MLP（Multilayer Perceptron，多层感知机）大行其道时，能设计出这样的模型已实属不易，也为后来CNN模型的发展奠定了基础。\u003C\u002Fp\u003E\u003Cp\u003E特点：\u003C\u002Fp\u003E\u003Cp\u003E1.相比MLP，LeNet使用了相对更少的参数，获得了更好的结果。\u003C\u002Fp\u003E\u003Cp\u003E2.设计了maxpool来提取特征\u003C\u002Fp\u003E\u003Ch2\u003E2 AlexNet\u003C\u002Fh2\u003E\u003Cp\u003EAlexNet是Hinton和他的学生Alex在2012设计的网络，并获得了当年的ImageNet竞赛冠军。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-51828e6a40c2a8fe150aefdf6a7a5fec_b.jpg\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"366\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-51828e6a40c2a8fe150aefdf6a7a5fec_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1080&#39; height=&#39;366&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"366\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-51828e6a40c2a8fe150aefdf6a7a5fec_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-51828e6a40c2a8fe150aefdf6a7a5fec_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图2.1: AlexNet网络\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-3f20a882478729c6ccf48c9e47541ffb_b.jpg\" data-size=\"normal\" data-rawwidth=\"446\" data-rawheight=\"692\" class=\"origin_image zh-lightbox-thumb\" width=\"446\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-3f20a882478729c6ccf48c9e47541ffb_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;446&#39; height=&#39;692&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"446\" data-rawheight=\"692\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"446\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-3f20a882478729c6ccf48c9e47541ffb_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-3f20a882478729c6ccf48c9e47541ffb_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图2.2: AlexNet网络\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E特点：\u003C\u002Fp\u003E\u003Cp\u003E1.相比LeNet，AlexNet设计了更深层的网络。\u003C\u002Fp\u003E\u003Cp\u003E2.在每个卷机后面添加了Relu激活函数，解决了Sigmoid的梯度消失问题，使收敛更快。\u003C\u002Fp\u003E\u003Cp\u003E3.添加了归一化LRN（Local Response Normalization，局部响应归一化）层，使准确率更高。\u003C\u002Fp\u003E\u003Cp\u003E4. 设计并使用了dropout层，减轻了模型的过拟合。\u003C\u002Fp\u003E\u003Cp\u003E5.通过裁剪，旋转等方式增强了训练数据。\u003C\u002Fp\u003E\u003Cp\u003E6.受于当时的算力限制，Alexnet创新地将图像分为上下两块分别训练，然后在全连接层合并在一起（AlexNet网络图1，可以看到有上下两部分）。\u003C\u002Fp\u003E\u003Ch2\u003E3 VGGNet\u003C\u002Fh2\u003E\u003Cp\u003EVGGNet在2014年的ImageNet比赛中，分别在定位和分类跟踪任务中取得第一名和第二名。VGGNet主要特点：\u003C\u002Fp\u003E\u003Cp\u003E1.探索了更深层次的网络结构图，可以看成是AlexNet的加强版本。\u003C\u002Fp\u003E\u003Cp\u003E2.在卷机设计上，使用了更小的卷机核，验证了小尺寸的卷机核在深度网络中，不仅减少了参数，也达到了更好的效果。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ab442f19d6e2328ac721cf8e552d04a9_b.jpg\" data-size=\"normal\" data-rawwidth=\"1044\" data-rawheight=\"988\" class=\"origin_image zh-lightbox-thumb\" width=\"1044\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ab442f19d6e2328ac721cf8e552d04a9_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1044&#39; height=&#39;988&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1044\" data-rawheight=\"988\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1044\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ab442f19d6e2328ac721cf8e552d04a9_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ab442f19d6e2328ac721cf8e552d04a9_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图3.1: VGGNet网络结构图\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Ch2\u003E4 GoogLeNet\u003C\u002Fh2\u003E\u003Cp\u003E\u003Cb\u003E4.1 GoogLeNet v1\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003EGoogLeNet v1版本诞生于2014年，在ILSVRC 比赛中获得冠军，其性能与同年诞生的VGG差不多，但参数量少于VGG。该模型并没有单纯的将网络加深，而是引入了Inception概念，\u003Cb\u003E通过多个卷积核提取图像不同尺度的信息，最后进行融合，可以得到图像更好的表征\u003C\u002Fb\u003E。\u003C\u002Fp\u003E\u003Cp\u003E特点：\u003C\u002Fp\u003E\u003Cp\u003E1.引入Inception概念，在当时流行模型‘加深’情况下，设计了‘加宽’的思路\u003C\u002Fp\u003E\u003Cp\u003E2.采用Network in Network中用Average pool来代替全连接层的思想。实际在最后一层还是添加了一个全连接层，是为了大家做finetune。\u003C\u002Fp\u003E\u003Cp\u003E3.另外增加了两个辅助的softmax分支，作用有两点，一是为了避免梯度消失，用于向前传导梯度。反向传播时如果有一层求导为0，链式求导结果则为0。二是将中间某一层输出用作分类，起到模型融合作用。最后的loss=loss_2 + 0.3 * loss_1 + 0.3 * loss_0。实际测试时，这两个辅助softmax分支会被去掉。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b3731d293a7775eab0203e4e0182b5d8_b.jpg\" data-size=\"normal\" data-rawwidth=\"324\" data-rawheight=\"284\" class=\"content_image\" width=\"324\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;324&#39; height=&#39;284&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"324\" data-rawheight=\"284\" class=\"content_image lazy\" width=\"324\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b3731d293a7775eab0203e4e0182b5d8_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图4.1: Inception\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-54468fc87ff65a25950db4f2dd8059a6_b.jpg\" data-size=\"normal\" data-rawwidth=\"716\" data-rawheight=\"410\" class=\"origin_image zh-lightbox-thumb\" width=\"716\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-54468fc87ff65a25950db4f2dd8059a6_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;716&#39; height=&#39;410&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"716\" data-rawheight=\"410\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"716\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-54468fc87ff65a25950db4f2dd8059a6_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-54468fc87ff65a25950db4f2dd8059a6_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图4.2\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-4a5d576e354b8d45b7e8c6a5b9880dc7_b.jpg\" data-size=\"normal\" class=\"content_image\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-4a5d576e354b8d45b7e8c6a5b9880dc7_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图4.3: GoogLeNet V1整体结构\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E4.2 GoogLeNet V2，V3\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003E在2015年，同篇论文中发布了 GoogLeNet V2和V3版本。\u003C\u002Fp\u003E\u003Cp\u003EV2特点：\u003C\u002Fp\u003E\u003Col\u003E\u003Cli\u003E学习VGGNet的特点，用两个3*3卷积代替5*5卷积，降低参数量，提高计算速度，从而提升性能。（下图Figure5）\u003C\u002Fli\u003E\u003Cli\u003E它们将滤波器大小nxn的卷积分解为1xn和nx1卷积的组合。例如，3x3卷积相当于首先执行1x3卷积，然后在其输出上执行3x1卷积。他们发现这种方法比单个3x3卷积便宜33％。（下图Figure6）\u003C\u002Fli\u003E\u003Cli\u003E模块中的滤波器组被扩展（更宽而不是更深）以消除代表性瓶颈。如果模块变得更深，则尺寸会过度减少，从而导致信息丢失。（下图Figure7）\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-74df852aea1b456a221a770baf29f5eb_b.jpg\" data-size=\"normal\" data-rawwidth=\"1278\" data-rawheight=\"394\" class=\"origin_image zh-lightbox-thumb\" width=\"1278\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-74df852aea1b456a221a770baf29f5eb_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1278&#39; height=&#39;394&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1278\" data-rawheight=\"394\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1278\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-74df852aea1b456a221a770baf29f5eb_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-74df852aea1b456a221a770baf29f5eb_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图4.4: 3种Inception结构\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f9e7addb312fe206538f519eb489a3f2_b.jpg\" data-size=\"normal\" data-rawwidth=\"592\" data-rawheight=\"514\" class=\"origin_image zh-lightbox-thumb\" width=\"592\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f9e7addb312fe206538f519eb489a3f2_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;592&#39; height=&#39;514&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"592\" data-rawheight=\"514\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"592\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f9e7addb312fe206538f519eb489a3f2_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f9e7addb312fe206538f519eb489a3f2_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图4.5: GoogLeNet v2结构\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EV3包含了为V2规定的所有上述改进，另外还使用了以下内容：\u003C\u002Fp\u003E\u003Col\u003E\u003Cli\u003ERMSProp优化器。\u003C\u002Fli\u003E\u003Cli\u003E学习Factorization into small convolutions的思想，将7x7分解成两个一维的卷积（1x7,7x1），3x3也是一样（1x3,3x1），这样的好处，既可以加速计算（多余的计算能力可以用来加深网络），又可以将1个conv拆成2个conv，使得网络深度进一步增加，增加了网络的非线性，还有值得注意的地方是网络输入从224x224变为了299x299，更加精细设计了35x35\u002F17x17\u002F8x8的模块。\u003C\u002Fli\u003E\u003Cli\u003E辅助分类器中的BatchNorm。BN算法是一个正则化方法，可以提高大网络的收敛速度。简单介绍一下BN算法。就是对输入层信息分布标准化处理，使得规范化为N(0,1)的高斯分布，收敛速度大大提高。\u003C\u002Fli\u003E\u003Cli\u003E标签平滑（添加到损失公式中的一种正规化组件，可防止网络对类过于自信。防止过度拟合）。\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp\u003E\u003Cb\u003E4.3 GoogLeNet V4 ，Inception-ResNet v1和v2\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-bbe93e6e4a1689ce0aba0eb18b0728f7_b.jpg\" data-size=\"normal\" data-rawwidth=\"1574\" data-rawheight=\"468\" class=\"origin_image zh-lightbox-thumb\" width=\"1574\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-bbe93e6e4a1689ce0aba0eb18b0728f7_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1574&#39; height=&#39;468&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1574\" data-rawheight=\"468\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1574\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-bbe93e6e4a1689ce0aba0eb18b0728f7_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-bbe93e6e4a1689ce0aba0eb18b0728f7_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图4.6: V4版本 3种Inception结构\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ad457161f29b2dc6823df321b3e5e865_b.jpg\" data-size=\"normal\" data-rawwidth=\"2360\" data-rawheight=\"568\" class=\"origin_image zh-lightbox-thumb\" width=\"2360\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ad457161f29b2dc6823df321b3e5e865_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2360&#39; height=&#39;568&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2360\" data-rawheight=\"568\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2360\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ad457161f29b2dc6823df321b3e5e865_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ad457161f29b2dc6823df321b3e5e865_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图4.7: 4种Reduction结构\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b029fbbf770f13cfb7590471f80e5c18_b.jpg\" data-size=\"normal\" data-rawwidth=\"1800\" data-rawheight=\"668\" class=\"origin_image zh-lightbox-thumb\" width=\"1800\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b029fbbf770f13cfb7590471f80e5c18_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1800&#39; height=&#39;668&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1800\" data-rawheight=\"668\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1800\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b029fbbf770f13cfb7590471f80e5c18_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b029fbbf770f13cfb7590471f80e5c18_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图4.8: 3种Inception-ResNet-V1结构\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c67390a307425fc2b136fce45df4a80f_b.jpg\" data-size=\"normal\" data-rawwidth=\"1736\" data-rawheight=\"752\" class=\"origin_image zh-lightbox-thumb\" width=\"1736\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c67390a307425fc2b136fce45df4a80f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1736&#39; height=&#39;752&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1736\" data-rawheight=\"752\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1736\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c67390a307425fc2b136fce45df4a80f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c67390a307425fc2b136fce45df4a80f_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图4.9: 3种Inception-ResNet-V2结构\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"small\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-6ba76fea791d6571e4801495697163e1_b.jpg\" data-size=\"small\" data-rawwidth=\"1222\" data-rawheight=\"1008\" class=\"origin_image zh-lightbox-thumb\" width=\"1222\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-6ba76fea791d6571e4801495697163e1_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1222&#39; height=&#39;1008&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"small\" data-rawwidth=\"1222\" data-rawheight=\"1008\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1222\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-6ba76fea791d6571e4801495697163e1_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-6ba76fea791d6571e4801495697163e1_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图4.10: Inception-ResNet结构中加入 Activation Scaling，防止网络“死亡”\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-b545bd70798a1efe3ae0e4ab5eee6f0b_b.jpg\" data-size=\"normal\" data-rawwidth=\"2436\" data-rawheight=\"1234\" class=\"origin_image zh-lightbox-thumb\" width=\"2436\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-b545bd70798a1efe3ae0e4ab5eee6f0b_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2436&#39; height=&#39;1234&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"2436\" data-rawheight=\"1234\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2436\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-b545bd70798a1efe3ae0e4ab5eee6f0b_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-b545bd70798a1efe3ae0e4ab5eee6f0b_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E4.11: Stem与最终网络结构图\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003EV4与之前的V3，V2版本主要改动有：\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Col\u003E\u003Cli\u003E修改了stem，这里的stem是指在引入Inception块之前执行的初始操作集。\u003C\u002Fli\u003E\u003Cli\u003EV4引入了专门的“Reduction Blocks”，用于改变网格的宽度和高度。早期版本没有显式Reduction Blocks，但实现了类似功能。\u003C\u002Fli\u003E\u003Cli\u003EV4版本的3种Inception与之前版本的3种Inception非常相似，但也做了细节的修改。\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Cp\u003E\u003Cb\u003EInception-ResNet V1和V2特点：\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Col\u003E\u003Cli\u003E在Inception设计中加入了ResNet思想。从图4.8和图4.9可以看到，V1和V2中的3种Inception-ResNet结构相同，不同的只是超参数。\u003C\u002Fli\u003E\u003Cli\u003EInception-ResNet V1与V2的整体结构不同，Inception-ResNet V1的计算成本与Inception v3类似，Inception-ResNet V2的计算成本与Inception v4类似。\u003C\u002Fli\u003E\u003Cli\u003E为了实现残差加法，卷积后的输入和输出必须具有相同的尺寸。因此，我们在Inception卷积之后使用1x1卷积来匹配深度大小（卷积后的深度增加）。\u003C\u002Fli\u003E\u003Cli\u003E主要Inception模块内的池化操作被替换为有利于残差连接。但是，您仍然可以在reduction blocks中找到这些操作。Reduction Block A与Inception v4中的相同。\u003C\u002Fli\u003E\u003Cli\u003E如果滤波器的数量超过1000，那么网络架构中更深的残差单元会导致网络“死亡”。因此，为了增加稳定性，作者将残差激活量调整，系数为0.1到0.3，如图4.10。\u003C\u002Fli\u003E\u003Cli\u003E为了在单个GPU上训练模型，原始论文在求和之后没有使用BatchNorm（以使整个模型适合单个GPU）。\u003C\u002Fli\u003E\u003Cli\u003E结果发现，Inception-ResNet模型能够再用较少的epoch时获得更高的精度。\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Ch2\u003E5 ResNet\u003C\u002Fh2\u003E\u003Cp\u003E随着算力的不断更新，越来越深的网络能够得到计算，但研究者发现随着网络的加深，模型变得越来越不能够训练，遇到了梯度消失或爆炸问题。在ResNet出现之前，人们通过BN，Relu等方式去缓解此问题，但仍然不能把网络做到足够深。\u003C\u002Fp\u003E\u003Cp\u003E15年何恺明提出了ResNet网络，该思路启发于LSTM的控制门的思想。\u003C\u002Fp\u003E\u003Cblockquote\u003Ey = H(x,WH)•T(x,WT) + X•(1- T(x,WT)) \u003C\u002Fblockquote\u003E\u003Cp\u003E可以看出，当T(x,WT) = 0，y=x，当T(x,WT) = 1，y= H(x,WH) \u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-6dd1d0a92ec60e33a5a13074e8108c6e_b.jpg\" data-size=\"normal\" data-rawwidth=\"438\" data-rawheight=\"242\" class=\"origin_image zh-lightbox-thumb\" width=\"438\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-6dd1d0a92ec60e33a5a13074e8108c6e_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;438&#39; height=&#39;242&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"438\" data-rawheight=\"242\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"438\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-6dd1d0a92ec60e33a5a13074e8108c6e_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-6dd1d0a92ec60e33a5a13074e8108c6e_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图5.1 ResNet中的block示意图\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E从图5.1可以看出：相比传统网络：y=f(x)，ResNet Block公式为：y=f(x) + x，可以称之为skip connect。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-30457c8c79506a27ca7756b82a7b2730_b.jpg\" data-size=\"normal\" data-rawwidth=\"808\" data-rawheight=\"404\" class=\"origin_image zh-lightbox-thumb\" width=\"808\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-30457c8c79506a27ca7756b82a7b2730_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;808&#39; height=&#39;404&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"808\" data-rawheight=\"404\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"808\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-30457c8c79506a27ca7756b82a7b2730_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-30457c8c79506a27ca7756b82a7b2730_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图5.2 ResNet网络中使用的两种Block\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-7aaa9fb90e2546cbc185893eed067a99_b.jpg\" data-size=\"normal\" data-rawwidth=\"1474\" data-rawheight=\"514\" class=\"origin_image zh-lightbox-thumb\" width=\"1474\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-7aaa9fb90e2546cbc185893eed067a99_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1474&#39; height=&#39;514&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1474\" data-rawheight=\"514\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1474\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-7aaa9fb90e2546cbc185893eed067a99_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-7aaa9fb90e2546cbc185893eed067a99_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图5.3 不同层数的ResNet设计方式\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4d0409256153f441477f9483ffc88a80_b.jpg\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"424\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4d0409256153f441477f9483ffc88a80_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1080&#39; height=&#39;424&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1080\" data-rawheight=\"424\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4d0409256153f441477f9483ffc88a80_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4d0409256153f441477f9483ffc88a80_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图5.4 34层ResNet与其他网络的比较\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cb\u003E题外话：\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003EOrhan等发表的论文《Skip connections eliminate singularities》提出\u003Cb\u003E神经网络的退化才是难以训练深层网络根本原因所在，而不是梯度消散\u003C\u002Fb\u003E。虽然梯度范数大，但是如果网络的可用自由度对这些范数的贡献非常不均衡，也就是每个层中只有少量的隐藏单元对不同的输入改变它们的激活值，而大部分隐藏单元对不同的输入都是相同的反应，此时整个权重矩阵的秩不高。并且随着网络层数的增加，连乘后使得整个秩变的更低。这也是我们常说的网络退化问题，虽然是一个很高维的矩阵，但是大部分维度却没有信息，表达能力没有看起来那么强大。残差连接正是强制打破了网络的对称性。总的来说一句话，打破了网络的对称性，提升了网络的表征能力。也可查看文献《Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units》。\u003C\u002Fp\u003E\u003Ch2\u003E\u003Cb\u003E6 DenseNet\u003C\u002Fb\u003E\u003C\u002Fh2\u003E\u003Cp\u003E从图6.1中可以看出，DenseNet是借鉴了ResNet，是ResNet的升级版，从上述ResNet可以看到，一般每个Block会有一个skip connect，而DenseNet会在每层conv间有一个skip connect。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5f7997b4679018b284834cad140d366d_b.jpg\" data-size=\"normal\" data-rawwidth=\"1152\" data-rawheight=\"436\" class=\"origin_image zh-lightbox-thumb\" width=\"1152\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5f7997b4679018b284834cad140d366d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1152&#39; height=&#39;436&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1152\" data-rawheight=\"436\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1152\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5f7997b4679018b284834cad140d366d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5f7997b4679018b284834cad140d366d_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图6.1 ResNet Block与DenseNetBlock区别\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"small\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-64d758c01b0578e9004bc725f7eb7b03_b.jpg\" data-size=\"small\" data-rawwidth=\"688\" data-rawheight=\"578\" class=\"origin_image zh-lightbox-thumb\" width=\"688\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-64d758c01b0578e9004bc725f7eb7b03_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;688&#39; height=&#39;578&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"small\" data-rawwidth=\"688\" data-rawheight=\"578\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"688\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-64d758c01b0578e9004bc725f7eb7b03_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-64d758c01b0578e9004bc725f7eb7b03_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图6.2DenseNet Block示意图\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a8a812f9cac80ff5da05b5de34ff019e_b.jpg\" data-size=\"normal\" data-rawwidth=\"1196\" data-rawheight=\"558\" class=\"origin_image zh-lightbox-thumb\" width=\"1196\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a8a812f9cac80ff5da05b5de34ff019e_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1196&#39; height=&#39;558&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1196\" data-rawheight=\"558\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1196\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a8a812f9cac80ff5da05b5de34ff019e_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a8a812f9cac80ff5da05b5de34ff019e_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图6.3 DenseNet 各网络结构图\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-f0c92f93668b600c04643bb8b65a7790_b.jpg\" data-size=\"normal\" data-rawwidth=\"1680\" data-rawheight=\"326\" class=\"origin_image zh-lightbox-thumb\" width=\"1680\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-f0c92f93668b600c04643bb8b65a7790_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1680&#39; height=&#39;326&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" data-rawwidth=\"1680\" data-rawheight=\"326\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1680\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-f0c92f93668b600c04643bb8b65a7790_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-f0c92f93668b600c04643bb8b65a7790_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图6.4 DenseNet 网络\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cblockquote\u003E神经网络越深，网络的能力越强，就越有可能过度学习数据集，导致过拟合。大家应该还记得，作为第一个深层网络Alexnet网络，它提出了重要的策略dropout，对于提高模型的泛化能力非常有效。alexnet网络至今仍然可以用于很多的任务，这足以说明其鲁棒性。后来BN和数据增强等正则化策略替代dropout也在一定程度上缓解了过拟合的问题。文《Deep networks with stochastic depth》（Huang G, Sun Y, Liu Z, et al. ）是DenseNet作者们早期的研究，它们通过训练时随机丢掉一些网络层，提高了ResNet的泛化性能。\u003Cbr\u002F\u003E从这里可以看出来一个重要特性，这也是神经网络中大家比较关心的问题，\u003Cb\u003E网络的冗余性绝对是存在的，而且不小\u003C\u002Fb\u003E，通过探索dropout值的比例对性能的影响可以去估算这个冗余。\u003Cbr\u002F\u003E既然丢掉某些层间连接或者整个层不影响性能，就说明这一层学习到的非线性转变很小，既然转变很小，那么每一层学习几百个通道，还有必要吗？这几百个通道，正是万恶的计算量所在。\u003Cbr\u002F\u003E\u003Cb\u003E考虑到这一点，densenet就同时做了两件事情，一是将网络中的每一层都直接与其前面层相连，提高特征的利用率；二是把网络的每一层设计得很窄，也就是卷积的输出通道数通常很小，只有几十，该层学习非常少的特征图并与输入concat使用。\u003C\u002Fb\u003E\u003Cbr\u002F\u003E这实现了资源的最大化利用和计算量的压缩。ImageNet分类数据集上达到同样的准确率，DenseNet 所需的参数量不到ResNet的一半，所需的计算量也只有ResNet的一半左右。\u003Cbr\u002F\u003E引用自\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fmp.weixin.qq.com\u002Fs%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029786%26idx%3D1%26sn%3D6b992921e6dd5cf15ae5d5bef16448d5%26chksm%3D871342e7b064cbf159b54a866d1887cbfb68648646bc6375859af7628cfca8ea7e50168f6723%26scene%3D21%23wechat_redirect\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E【模型解读】“全连接”的卷积网络，有什么好？\u003C\u002Fa\u003E\u003C\u002Fblockquote\u003E\u003Ch2\u003E7 Non-Local Networks\u003C\u002Fh2\u003E\u003Cp\u003ENon-Local Networks启发于non-local means滤波算法，该滤波算法是经典的图像去噪算法之一。在CNN模型中不论是conv层还是pool层（全局pool除外），它们对数据的感受野都是局部的。为了增大conv或pool的感受野，传统方式是增加网络的深度（网络越深，后面conv和pool的感受野越大），但这样会增加训练的难度（越深越难训练），而且降低效率（参数增加）。该论文提出的Non-local Networks可以在每层计算中参考全局信息。\u003C\u002Fp\u003E\u003Cp\u003E该方法属于\u003Cb\u003E自注意力机制\u003C\u002Fb\u003E的范畴\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"small\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-001eea370bb4350424ae6be8c440c5be_b.jpg\" data-size=\"small\" data-rawwidth=\"1080\" data-rawheight=\"1038\" class=\"origin_image zh-lightbox-thumb\" width=\"1080\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-001eea370bb4350424ae6be8c440c5be_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1080&#39; height=&#39;1038&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"small\" data-rawwidth=\"1080\" data-rawheight=\"1038\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1080\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-001eea370bb4350424ae6be8c440c5be_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-001eea370bb4350424ae6be8c440c5be_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图7.1 non-local means 滤波示意图：non-local顾名思义，将这个邻域扩展到全图。如上图p作为中心像素，q1，q2，q3对p的滤波都有贡献，实际上图像上任意一个点都有贡献。\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"small\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-1a5d798940278c7b8032c7f186173247_b.jpg\" data-size=\"small\" data-rawwidth=\"684\" data-rawheight=\"726\" class=\"origin_image zh-lightbox-thumb\" width=\"684\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-1a5d798940278c7b8032c7f186173247_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;684&#39; height=&#39;726&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"small\" data-rawwidth=\"684\" data-rawheight=\"726\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"684\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-1a5d798940278c7b8032c7f186173247_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-1a5d798940278c7b8032c7f186173247_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图7.2 None-local的实现方式\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"small\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8ccda905605caf47dd3ef647b192a5e9_b.jpg\" data-size=\"small\" data-rawwidth=\"710\" data-rawheight=\"326\" class=\"origin_image zh-lightbox-thumb\" width=\"710\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8ccda905605caf47dd3ef647b192a5e9_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;710&#39; height=&#39;326&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"small\" data-rawwidth=\"710\" data-rawheight=\"326\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"710\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8ccda905605caf47dd3ef647b192a5e9_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8ccda905605caf47dd3ef647b192a5e9_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图7.3 None-local公式\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003ENon-Local Networks 代码（pytorch）：\u003C\u002Fp\u003E\u003Cdiv class=\"highlight\"\u003E\u003Cpre\u003E\u003Ccode class=\"language-text\"\u003Eself.g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1, stride=1, padding=0)\nself.theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1, stride=1, padding=0)\nself.phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1, stride=1, padding=0)\nself.W = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels, kernel_size=1, stride=1, padding=0)\n\n\ng_x = self.g(x).view(batch_size, self.inter_channels, -1).permute(0, 2, 1)\ntheta_x = self.theta(x).view(batch_size, self.inter_channels, -1).permute(0, 2, 1)\nphi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\nf = torch.matmul(theta_x, phi_x)\nf_div_C = F.softmax(f, dim=-1)\ny = torch.matmul(f_div_C, g_x).permute(0, 2, 1).contiguous()\ny = y.view(batch_size, self.inter_channels, *x.size()[2:])\nW_y = self.W(y)\nz = W_y + x\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003Cfigure data-size=\"small\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d437f2b458e12cd0074b80e240a8c83f_b.jpg\" data-size=\"small\" data-rawwidth=\"764\" data-rawheight=\"630\" class=\"origin_image zh-lightbox-thumb\" width=\"764\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d437f2b458e12cd0074b80e240a8c83f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;764&#39; height=&#39;630&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"small\" data-rawwidth=\"764\" data-rawheight=\"630\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"764\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d437f2b458e12cd0074b80e240a8c83f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-d437f2b458e12cd0074b80e240a8c83f_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图7.4 Non-local 网络结构\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E特点：\u003C\u002Fp\u003E\u003Col\u003E\u003Cli\u003E对于视频分类，non-local会好于相应的一般网络，毕竟没有大的感受野未必能很鲁棒的捕捉一个动作到底是跳高还是跳水。\u003C\u002Fli\u003E\u003Cli\u003E依据作者们的结论，在网络浅层效果会更好，毕竟随着网络深度增加，传统网络感受野也会增加了，Non-local的效果也就不再明显。\u003C\u002Fli\u003E\u003C\u002Fol\u003E\u003Ch2\u003E8 Deformable Convolutional Networks\u003C\u002Fh2\u003E\u003Cp\u003E同样的物体在图像中可能呈现出不同的大小、姿态、视角变化甚至非刚体形变，如何适应这些复杂的几何形变是物体识别的主要难点。而Deformable Conv模型尝试着解决这类问题。\u003C\u002Fp\u003E\u003Cblockquote\u003E首次在卷积神经网络（convolutional neutral networks，CNN）中引入了学习空间几何形变的能力，得到可变形卷积网络（deformable convolutional networks），从而更好地解决了具有空间形变的图像识别任务。研究员们通过大量的实验结果验证了该方法在复杂的计算机视觉任务（如目标检测和语义分割）上的有效性，首次表明在深度卷积神经网络（deep CNN）中学习空间上密集的几何形变是可行的。\u003Cbr\u002F\u003E作者：微软亚洲研究院\u003Cbr\u002F\u003E链接：\u003Ca href=\"https:\u002F\u002Fwww.zhihu.com\u002Fquestion\u002F57493889\u002Fanswer\u002F184578752\" class=\"internal\"\u003E\u003Cspan class=\"invisible\"\u003Ehttps:\u002F\u002Fwww.\u003C\u002Fspan\u003E\u003Cspan class=\"visible\"\u003Ezhihu.com\u002Fquestion\u002F5749\u003C\u002Fspan\u003E\u003Cspan class=\"invisible\"\u003E3889\u002Fanswer\u002F184578752\u003C\u002Fspan\u003E\u003Cspan class=\"ellipsis\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003C\u002Fblockquote\u003E\u003Cp\u003E当前深度模型对物体的几何形变适应能力几乎还是来自于数据本身的多样性，模型内部并不具有适应几何形变的机制。作者认为造成这样的问题是卷积操作本身就是固定的几何结构。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9d28f60a0566871bff39f146d88d946e_b.jpg\" data-size=\"normal\" class=\"content_image\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;0&#39; height=&#39;0&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"normal\" class=\"content_image lazy\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9d28f60a0566871bff39f146d88d946e_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图7.5 展示了卷积核大小为 3x3 的正常卷积和可变形卷积的采样方式，(a) 所示的正常卷积规律的采样 9 个点（绿点），(b)(c)(d) 为可变形卷积，在正常的采样坐标上加上一个位移量（蓝色箭头），其中(c)(d) 作为 (b) 的特殊情况，展示了可变形卷积可以作为尺度变换，比例变换和旋转变换的特殊情况作\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"small\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1d2996b769d919a2487f7b160bb750b5_b.jpg\" data-size=\"small\" data-rawwidth=\"656\" data-rawheight=\"356\" class=\"origin_image zh-lightbox-thumb\" width=\"656\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1d2996b769d919a2487f7b160bb750b5_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;656&#39; height=&#39;356&#39;&gt;&lt;\u002Fsvg&gt;\" data-size=\"small\" data-rawwidth=\"656\" data-rawheight=\"356\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"656\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1d2996b769d919a2487f7b160bb750b5_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1d2996b769d919a2487f7b160bb750b5_b.jpg\"\u002F\u003E\u003Cfigcaption\u003E图7.6 示例图\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"small\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-6274ab76f6a644ecf5bed200ceea2a5b_b.jpg\" data-caption=\"\" data-size=\"small\" data-rawwidth=\"628\" data-rawheight=\"464\" class=\"origin_image zh-lightbox-thumb\" width=\"628\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-6274ab76f6a644ecf5bed200ceea2a5b_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;628&#39; height=&#39;464&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"small\" data-rawwidth=\"628\" data-rawheight=\"464\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"628\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-6274ab76f6a644ecf5bed200ceea2a5b_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-6274ab76f6a644ecf5bed200ceea2a5b_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"small\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-b62eceececd70d1272642365e707c802_b.jpg\" data-caption=\"\" data-size=\"small\" data-rawwidth=\"666\" data-rawheight=\"464\" class=\"origin_image zh-lightbox-thumb\" width=\"666\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-b62eceececd70d1272642365e707c802_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;666&#39; height=&#39;464&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"small\" data-rawwidth=\"666\" data-rawheight=\"464\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"666\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-b62eceececd70d1272642365e707c802_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-b62eceececd70d1272642365e707c802_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Ch2\u003E9 Dilated Convolutional Networks\u003C\u002Fh2\u003E\u003Cp\u003EDilated Convolution 被中文翻译为“空洞卷积”或“膨胀卷积”，我更倾向于称之为“膨胀卷积”。该模型最早由\u003Cb\u003EFisher Yu\u003C\u002Fb\u003E在2016年ICLR上发表的论文《Multi-Scale Context Aggregation by Dilation Convolutions》中提出。该模型最早应用于图像分割，因为传统CNN模型需要通过pooling层来缩小图像尺寸，并扩大下一层的感受野，即进行下采样（down sampling）；这一过程肯定会有信息丢失。因为图像分割是pixel-wise的，且在图像预测时还需要进行上采样（up sampling）操作，丢失的信息在上采样过程中也很难再找回。\u003C\u002Fp\u003E\u003Cp\u003E为了解决上述问题，\u003Cb\u003EFisher Yu\u003C\u002Fb\u003E提出了Dilated Convolution方法，通过Dilated Convolution来替代pooling层进行下采样操作，不仅扩大了感受野，也不会丢失信息。\u003C\u002Fp\u003E\u003Cp\u003E下面看一下dilated conv原始论文中的示意图：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-3c9df966ee79c38dd24b016856a2a328_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1754\" data-rawheight=\"914\" class=\"origin_image zh-lightbox-thumb\" width=\"1754\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-3c9df966ee79c38dd24b016856a2a328_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1754&#39; height=&#39;914&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1754\" data-rawheight=\"914\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1754\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-3c9df966ee79c38dd24b016856a2a328_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-3c9df966ee79c38dd24b016856a2a328_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E(a)图对应3x3的1-dilated conv，和普通的卷积操作一样，(b)图对应3x3的2-dilated conv，实际的卷积kernel size还是3x3，但是空洞为1，也就是对于一个7x7的图像patch，只有9个红色的点和3x3的kernel发生卷积操作，其余的点略过。也可以理解为kernel的size为7x7，但是只有图中的9个点的权重不为0，其余都为0。 可以看到虽然kernel size只有3x3，但是这个卷积的感受野已经增大到了7x7（如果考虑到这个2-dilated conv的前一层是一个1-dilated conv的话，那么每个红点就是1-dilated的卷积输出，所以感受野为3x3，所以1-dilated和2-dilated合起来就能达到7x7的conv）,(c)图是4-dilated conv操作，同理跟在两个1-dilated和2-dilated conv的后面，能达到15x15的感受野。对比传统的conv操作，3层3x3的卷积加起来，stride为1的话，只能达到(kernel-1)*layer+1=7的感受野，也就是和层数layer成线性关系，而dilated conv的感受野是指数级的增长。\u003C\u002Fp\u003E\u003Cp\u003E\u003Cb\u003E10 SENET\u003C\u002Fb\u003E\u003C\u002Fp\u003E\u003Cp\u003ESENET在ImageNet 2017中的Image Classification夺得冠军。并在CVPR 2017中发表论文《Squeeze-and-excitation networks》。\u003C\u002Fp\u003E\u003Cp\u003E作者大概总结了前人对CNN模型的改进：卷积核作为卷积神经网络的核心，通常被看做是在局部感受野上，将空间上（spatial）的信息和特征维度上（channel-wise）的信息进行聚合的信息聚合体。卷积神经网络由一系列卷积层、非线性层和下采样层构成，这样它们能够从全局感受野上去捕获图像的特征来进行图像的描述。\u003C\u002Fp\u003E\u003Cp\u003E近很多工作被提出来从空间维度层面来提升网络的性能，如Inception结构中嵌入了多尺度信息，聚合多种不同感受野上的特征来获得性能增益；还如Non-local，deformable conv，dilated conv等都是在空间层面进行改进。\u003C\u002Fp\u003E\u003Cp\u003E本文提到的SENet另辟蹊径，尝试着从channel特征中寻找优化点。作者认为在每层卷积中输出的每个channel，其信息重要性是不同的，我们需要为每个channel的feature map设置一个权重，来重新量化每个channel的特征信息。作者的设计如下图所示：\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1bd3675aed6d5417bfb358d08fc9e8f4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2144\" data-rawheight=\"532\" class=\"origin_image zh-lightbox-thumb\" width=\"2144\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1bd3675aed6d5417bfb358d08fc9e8f4_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2144&#39; height=&#39;532&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2144\" data-rawheight=\"532\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2144\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1bd3675aed6d5417bfb358d08fc9e8f4_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1bd3675aed6d5417bfb358d08fc9e8f4_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E图中Fsq为Squeeze操作，将每个二维的特征通道变成一个实数，这个实数某种程度上具有全局的感受野，并且输出的维度和输入的特征通道数相匹配。\u003C\u002Fp\u003E\u003Cp\u003E图中Fex为Excitation操作，它是一个类似于循环神经网络中门的机制。通过参数 来为每个特征通道生成权重，其中参数 被学习用来显式地建模特征通道间的相关性。\u003C\u002Fp\u003E\u003Cp\u003E图中Fscale是一个Reweight操作。完成了每个channel的特征图权重计算。\u003C\u002Fp\u003E\u003Cp\u003ESE作为一个模块，可以跟其他CNN模型进行组合使用，下图是分别于Inception和ResNet进行组合\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-02554d51a722bb6bfea8f2f672a46cea_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2242\" data-rawheight=\"866\" class=\"origin_image zh-lightbox-thumb\" width=\"2242\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-02554d51a722bb6bfea8f2f672a46cea_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;2242&#39; height=&#39;866&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"2242\" data-rawheight=\"866\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"2242\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-02554d51a722bb6bfea8f2f672a46cea_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-02554d51a722bb6bfea8f2f672a46cea_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp\u003E参考文献：\u003C\u002Fp\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fmp.weixin.qq.com\u002Fs\u002FIMkvod2Lj2VOIWbFtAirzA\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-037f7f002fec0319694f70591f204804_180x120.jpg\" data-image-width=\"832\" data-image-height=\"467\" class=\" wrap external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E想入门设计卷积神经网络？这是一份综合设计指南\u003C\u002Fa\u003E\u003Ca href=\"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F45189981\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6b8b7a6a91978129edac137035860c24_180x120.jpg\" data-image-width=\"720\" data-image-height=\"284\" class=\"internal\"\u003E深度智能：InceptionNet 从v1到v4的演变\u003C\u002Fa\u003E\u003Ca href=\"https:\u002F\u002Fwww.zhihu.com\u002Fquestion\u002F312556066\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\"internal\"\u003E卷积神经网络（CNN）的结构设计都有哪些思想？\u003C\u002Fa\u003E\u003Ca href=\"https:\u002F\u002Flink.zhihu.com\u002F?target=https%3A\u002F\u002Fmp.weixin.qq.com\u002Fs%3F__biz%3DMzA3NDIyMjM1NA%3D%3D%26mid%3D2649029645%26idx%3D1%26sn%3D75b494ec181fee3e8756bb0fa119e7ce%26chksm%3D87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07%26scene%3D21%23wechat_redirect\" data-draft-node=\"block\" data-draft-type=\"link-card\" class=\" external\" target=\"_blank\" rel=\"nofollow noreferrer\"\u003E\u003Cspan class=\"invisible\"\u003Ehttps:\u002F\u002F\u003C\u002Fspan\u003E\u003Cspan class=\"visible\"\u003Emp.weixin.qq.com\u002Fs?\u003C\u002Fspan\u003E\u003Cspan class=\"invisible\"\u003E__biz=MzA3NDIyMjM1NA==&amp;mid=2649029645&amp;idx=1&amp;sn=75b494ec181fee3e8756bb0fa119e7ce&amp;chksm=87134270b064cb66aea66e73b4a6dc283d5750cfa9d331015424f075ba117e38f857d2f25d07&amp;scene=21#wechat_redirect\u003C\u002Fspan\u003E\u003Cspan class=\"ellipsis\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003Ca href=\"https:\u002F\u002Fwww.zhihu.com\u002Fquestion\u002F57493889\u002Fanswer\u002F184578752\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9d28f60a0566871bff39f146d88d946e_180x120.jpg\" data-image-width=\"640\" data-image-height=\"229\" class=\"internal\"\u003E如何评价 MSRA 最新的 Deformable Convolutional Networks？\u003C\u002Fa\u003E\u003Ca href=\"https:\u002F\u002Fwww.zhihu.com\u002Fquestion\u002F54149221\u002Fanswer\u002F192025860\" data-draft-node=\"block\" data-draft-type=\"link-card\" data-image=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-036913d7176af92daffcd60698751397_180x120.jpg\" data-image-width=\"869\" data-image-height=\"720\" class=\"internal\"\u003E如何理解空洞卷积（dilated convolution）？\u003C\u002Fa\u003E\u003Cp\u003E\u003Cbr\u002F\u003E                                         \u003Ca href=\"https:\u002F\u002Fwww.zhihu.com\u002Fquestion\u002F63460684\u002Fanswer\u002F300021819\" class=\"internal\"\u003E\u003Cspan class=\"invisible\"\u003Ehttps:\u002F\u002Fwww.\u003C\u002Fspan\u003E\u003Cspan class=\"visible\"\u003Ezhihu.com\u002Fquestion\u002F6346\u003C\u002Fspan\u003E\u003Cspan class=\"invisible\"\u003E0684\u002Fanswer\u002F300021819\u003C\u002Fspan\u003E\u003Cspan class=\"ellipsis\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20043586","type":"topic","id":"20043586","name":"卷积神经网络（CNN）"}],"voteupCount":318,"voting":0,"column":{"description":"","canManage":false,"intro":"","isFollowing":false,"urlToken":"c_1123912990784966656","id":"c_1123912990784966656","articlesCount":7,"acceptSubmission":true,"title":"计算机视觉学习笔记","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_1123912990784966656","commentPermission":"all","created":1560741738,"updated":1560763541,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002F4b70deef7_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002F0a900ad0d691e76a0ba1d5a5306698a1_{size}.jpg","uid":"73502124146688","userType":"people","isFollowing":false,"urlToken":"liuyuemaicha","id":"3ace18227686ca3672d6024be1b0d0f5","description":"","name":"KevinCK","isAdvertiser":false,"headline":"徘徊前进的男程，关注CV领域","gender":1,"url":"\u002Fpeople\u002F3ace18227686ca3672d6024be1b0d0f5","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002F0a900ad0d691e76a0ba1d5a5306698a1_l.jpg","isOrg":false,"type":"people"},"followers":170,"type":"column"},"commentCount":8,"contributions":[{"id":21084755,"state":"accepted","type":"include","column":{"description":"","canManage":false,"intro":"","isFollowing":false,"urlToken":"c_1123912990784966656","id":"c_1123912990784966656","articlesCount":7,"acceptSubmission":true,"title":"计算机视觉学习笔记","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_1123912990784966656","commentPermission":"all","created":1560741738,"updated":1560763541,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002F4b70deef7_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002F0a900ad0d691e76a0ba1d5a5306698a1_{size}.jpg","uid":"73502124146688","userType":"people","isFollowing":false,"urlToken":"liuyuemaicha","id":"3ace18227686ca3672d6024be1b0d0f5","description":"","name":"KevinCK","isAdvertiser":false,"headline":"徘徊前进的男程，关注CV领域","gender":1,"url":"\u002Fpeople\u002F3ace18227686ca3672d6024be1b0d0f5","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002F0a900ad0d691e76a0ba1d5a5306698a1_l.jpg","isOrg":false,"type":"people"},"followers":170,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":true,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"isNormal":true,"status":0,"shareText":"CNN系列模型发展简述（附github代码——已全部跑通） - 来自知乎专栏「计算机视觉学习笔记」，作者: KevinCK https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F66215918 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""}}},"columns":{"c_1123912990784966656":{"description":"","canManage":false,"intro":"","isFollowing":false,"urlToken":"c_1123912990784966656","id":"c_1123912990784966656","articlesCount":7,"acceptSubmission":true,"title":"计算机视觉学习笔记","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_1123912990784966656","commentPermission":"all","created":1560741738,"updated":1560763541,"imageUrl":"https:\u002F\u002Fpic2.zhimg.com\u002F4b70deef7_b.jpg","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic4.zhimg.com\u002F0a900ad0d691e76a0ba1d5a5306698a1_{size}.jpg","uid":"73502124146688","userType":"people","isFollowing":false,"urlToken":"liuyuemaicha","id":"3ace18227686ca3672d6024be1b0d0f5","description":"","name":"KevinCK","isAdvertiser":false,"headline":"徘徊前进的男程，关注CV领域","gender":1,"url":"\u002Fpeople\u002F3ace18227686ca3672d6024be1b0d0f5","avatarUrl":"https:\u002F\u002Fpic4.zhimg.com\u002F0a900ad0d691e76a0ba1d5a5306698a1_l.jpg","isOrg":false,"type":"people"},"followers":170,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{}},"currentUser":"","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false}},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{}},"env":{"ab":{"config":{"experiments":[{"expId":"launch-us_foltopic_user-10","expPrefix":"us_foltopic_user","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false},{"expId":"launch-vd_griffith-2","expPrefix":"vd_griffith","isDynamicallyUpdated":true,"isRuntime":false,"includeTriggerInfo":false}],"params":[{"id":"pf_feed","type":"String","value":"1","chainId":"_all_"},{"id":"se_wannasearch","type":"String","value":"0","chainId":"_all_"},{"id":"zr_infinity_a_u","type":"String","value":"close","chainId":"_all_"},{"id":"zr_video_rank","type":"String","value":"new_rank","chainId":"_all_"},{"id":"ls_new_upload","type":"String","value":"0","chainId":"_all_"},{"id":"se_movietab","type":"String","value":"0","chainId":"_all_"},{"id":"top_native_answer","type":"String","value":"1","chainId":"_all_"},{"id":"se_zu_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"zr_ans_rec","type":"String","value":"gbrank","chainId":"_all_"},{"id":"li_se_new_fields","type":"String","value":"0","chainId":"_all_"},{"id":"se_go_ztext","type":"String","value":"0","chainId":"_all_"},{"id":"se_time_threshold","type":"String","value":"0","chainId":"_all_"},{"id":"se_websearch","type":"String","value":"3","chainId":"_all_"},{"id":"top_rank","type":"String","value":"0","chainId":"_all_"},{"id":"se_subtext","type":"String","value":"0","chainId":"_all_"},{"id":"se_topic_pu","type":"String","value":"0","chainId":"_all_"},{"id":"soc_bignew","type":"String","value":"1","chainId":"_all_"},{"id":"top_hotcommerce","type":"String","value":"1","chainId":"_all_"},{"id":"se_ltr_v011","type":"String","value":"0","chainId":"_all_"},{"id":"se_p_slideshow","type":"String","value":"0","chainId":"_all_"},{"id":"top_vipconsume","type":"String","value":"1","chainId":"_all_"},{"id":"zr_ebook_chapter","type":"String","value":"0","chainId":"_all_"},{"id":"zr_es_update","type":"String","value":"0","chainId":"_all_"},{"id":"zr_km_xgb_model","type":"String","value":"new_xgb","chainId":"_all_"},{"id":"li_ts_sample","type":"String","value":"old","chainId":"_all_"},{"id":"top_recall_exp_v1","type":"String","value":"1","chainId":"_all_"},{"id":"tp_meta_card","type":"String","value":"0","chainId":"_all_"},{"id":"ug_follow_topic_1","type":"String","value":"2","chainId":"_all_"},{"id":"li_album_liutongab","type":"String","value":"0","chainId":"_all_"},{"id":"se_backsearch","type":"String","value":"0","chainId":"_all_"},{"id":"top_ydyq","type":"String","value":"X","chainId":"_all_"},{"id":"ug_follow_answerer_0","type":"String","value":"0","chainId":"_all_"},{"id":"se_billboardsearch","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sticky_android","type":"String","value":"0","chainId":"_all_"},{"id":"li_ebook_detail","type":"String","value":"1","chainId":"_all_"},{"id":"pf_noti_entry_num","type":"String","value":"0","chainId":"_all_"},{"id":"se_auto_syn","type":"String","value":"0","chainId":"_all_"},{"id":"se_whitelist","type":"String","value":"0","chainId":"_all_"},{"id":"ls_videoad","type":"String","value":"0","chainId":"_all_"},{"id":"se_college","type":"String","value":"default","chainId":"_all_"},{"id":"se_preset_tech","type":"String","value":"0","chainId":"_all_"},{"id":"se_webmajorob","type":"String","value":"0","chainId":"_all_"},{"id":"se_expired_ob","type":"String","value":"0","chainId":"_all_"},{"id":"se_amovietab","type":"String","value":"0","chainId":"_all_"},{"id":"web_wx_block","type":"String","value":"2"},{"id":"zr_search_xgb","type":"String","value":"0","chainId":"_all_"},{"id":"gue_zhuantikapian","type":"String","value":"0"},{"id":"tp_m_intro_re_topic","type":"String","value":"1","chainId":"_all_"},{"id":"se_terminate","type":"String","value":"0","chainId":"_all_"},{"id":"se_title_only","type":"String","value":"0","chainId":"_all_"},{"id":"top_recall_exp_v2","type":"String","value":"1","chainId":"_all_"},{"id":"web_sem_ab","type":"String","value":"0"},{"id":"gue_anonymous","type":"String","value":"show"},{"id":"se_famous","type":"String","value":"1","chainId":"_all_"},{"id":"se_site_onebox","type":"String","value":"0","chainId":"_all_"},{"id":"se_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"zr_video_recall","type":"String","value":"current_recall","chainId":"_all_"},{"id":"se_time_score","type":"String","value":"1","chainId":"_all_"},{"id":"tsp_lastread","type":"String","value":"0","chainId":"_all_"},{"id":"ug_goodcomment_0","type":"String","value":"1","chainId":"_all_"},{"id":"ug_zero_follow_0","type":"String","value":"0","chainId":"_all_"},{"id":"se_rr","type":"String","value":"0","chainId":"_all_"},{"id":"soc_special","type":"String","value":"0","chainId":"_all_"},{"id":"web_column_auto_invite","type":"String","value":"0"},{"id":"gue_new_special_page","type":"String","value":"0"},{"id":"pf_creator_card","type":"String","value":"1","chainId":"_all_"},{"id":"qa_answerlist_ad","type":"String","value":"0","chainId":"_all_"},{"id":"se_lottery","type":"String","value":"0","chainId":"_all_"},{"id":"tp_sft","type":"String","value":"a","chainId":"_all_"},{"id":"tsp_childbillboard","type":"String","value":"1","chainId":"_all_"},{"id":"ug_follow_answerer","type":"String","value":"0","chainId":"_all_"},{"id":"li_price_test","type":"String","value":"1","chainId":"_all_"},{"id":"se_colorfultab","type":"String","value":"1","chainId":"_all_"},{"id":"top_v_album","type":"String","value":"1","chainId":"_all_"},{"id":"tp_qa_toast","type":"String","value":"1","chainId":"_all_"},{"id":"tp_sft_v2","type":"String","value":" a","chainId":"_all_"},{"id":"ug_newtag","type":"String","value":"0","chainId":"_all_"},{"id":"web_question_invite","type":"String","value":"B"},{"id":"zr_km_slot_style","type":"String","value":"event_card","chainId":"_all_"},{"id":"pf_newguide_vertical","type":"String","value":"0","chainId":"_all_"},{"id":"se_college_cm","type":"String","value":"0","chainId":"_all_"},{"id":"se_timebox_num","type":"String","value":"3","chainId":"_all_"},{"id":"se_waterfall","type":"String","value":"0","chainId":"_all_"},{"id":"top_root","type":"String","value":"0","chainId":"_all_"},{"id":"zr_article_rec_rank","type":"String","value":"close","chainId":"_all_"},{"id":"pf_foltopic_usernum","type":"String","value":"50","chainId":"_all_"},{"id":"se_likebutton","type":"String","value":"0","chainId":"_all_"},{"id":"se_ltr_v010","type":"String","value":"1","chainId":"_all_"},{"id":"soc_bigone","type":"String","value":"0","chainId":"_all_"},{"id":"web_answer_list_ad","type":"String","value":"1"},{"id":"zr_km_style","type":"String","value":"base","chainId":"_all_"},{"id":"li_tjys_ec_ab","type":"String","value":"0","chainId":"_all_"},{"id":"se_search_feed","type":"String","value":"N","chainId":"_all_"},{"id":"se_topicdirect","type":"String","value":"2","chainId":"_all_"},{"id":"top_quality","type":"String","value":"0","chainId":"_all_"},{"id":"top_recall_deep_user","type":"String","value":"1","chainId":"_all_"},{"id":"ug_fw_answ_aut_1","type":"String","value":"0","chainId":"_all_"},{"id":"zr_km_answer","type":"String","value":"open_cvr","chainId":"_all_"},{"id":"li_hot_score_ab","type":"String","value":"0","chainId":"_all_"},{"id":"se_webtimebox","type":"String","value":"0","chainId":"_all_"},{"id":"soc_update","type":"String","value":"1","chainId":"_all_"},{"id":"top_reason","type":"String","value":"1","chainId":"_all_"},{"id":"li_android_vip","type":"String","value":"0","chainId":"_all_"},{"id":"li_qa_new_cover","type":"String","value":"0","chainId":"_all_"},{"id":"se_featured","type":"String","value":"1","chainId":"_all_"},{"id":"se_page_limit_20","type":"String","value":"1","chainId":"_all_"},{"id":"se_payconsult_click","type":"String","value":"0","chainId":"_all_"},{"id":"top_test_4_liguangyi","type":"String","value":"1","chainId":"_all_"},{"id":"ls_fmp4","type":"String","value":"1","chainId":"_all_"},{"id":"qa_test","type":"String","value":"0","chainId":"_all_"},{"id":"se_agency","type":"String","value":" 0","chainId":"_all_"},{"id":"se_ltr_v002","type":"String","value":"1","chainId":"_all_"},{"id":"se_new_topic","type":"String","value":"0","chainId":"_all_"},{"id":"web_heifetz_grow_ad","type":"String","value":"1"},{"id":"se_mobileweb","type":"String","value":"1","chainId":"_all_"},{"id":"se_topic_express","type":"String","value":"0","chainId":"_all_"},{"id":"web_answer_update","type":"String","value":"0"},{"id":"tp_qa_metacard","type":"String","value":"1","chainId":"_all_"},{"id":"se_limit","type":"String","value":"0","chainId":"_all_"},{"id":"se_pyc_click2","type":"String","value":"1","chainId":"_all_"},{"id":"top_ebook","type":"String","value":"0","chainId":"_all_"},{"id":"top_new_feed","type":"String","value":"5","chainId":"_all_"},{"id":"se_payconsult","type":"String","value":"0","chainId":"_all_"},{"id":"se_webrs","type":"String","value":"1","chainId":"_all_"},{"id":"top_universalebook","type":"String","value":"1","chainId":"_all_"},{"id":"zr_rel_search","type":"String","value":"base","chainId":"_all_"},{"id":"tp_qa_metacard_top","type":"String","value":"top","chainId":"_all_"},{"id":"tsp_hotctr","type":"String","value":"1","chainId":"_all_"},{"id":"web_answerlist_ad","type":"String","value":"0"},{"id":"zr_video_rank_nn","type":"String","value":"current_rank","chainId":"_all_"},{"id":"li_album3_ab","type":"String","value":"0","chainId":"_all_"},{"id":"se_zu_recommend","type":"String","value":"0","chainId":"_all_"},{"id":"top_gr_ab","type":"String","value":"0","chainId":"_all_"},{"id":"tp_header_style","type":"String","value":"1","chainId":"_all_"},{"id":"li_qa_cover","type":"String","value":"old","chainId":"_all_"},{"id":"se_ios_spb309","type":"String","value":"0","chainId":"_all_"},{"id":"web_n_web_msg","type":"String","value":"0"},{"id":"zr_art_rec","type":"String","value":"base","chainId":"_all_"},{"id":"pf_fuceng","type":"String","value":"1","chainId":"_all_"},{"id":"se_ad_index","type":"String","value":"10","chainId":"_all_"},{"id":"se_ri","type":"String","value":"0","chainId":"_all_"},{"id":"ug_zero_follow","type":"String","value":"0","chainId":"_all_"}],"chains":[{"chainId":"_all_"}]},"triggers":{}},"userAgent":{"Edge":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":false,"Android":false,"iOS":false,"isAppleDevice":false,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"isWebView":false,"origin":"Mozilla\u002F5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F75.0.3770.100 Safari\u002F537.36"},"ctx":{"path":"\u002Fp\u002F66215918"},"trafficSource":"production","edition":{"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false},"theme":"light","enableShortcut":true,"referer":"https:\u002F\u002Fgithub.com\u002Fliuyuemaicha\u002Fcnn_model","conf":{},"ipInfo":{"cityName":"unknown","countryName":"China","regionName":"Taiwan","countryCode":"TW"},"logged":false,"tdkInfo":{}},"me":{"accountInfoLoadStatus":{},"organizationProfileStatus":{},"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"active":{"sendDigitsError":null,"activeConfirmSucceeded":null,"activeConfirmError":null},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false,"captchaBase64String":null,"captchaValidationMessage":null,"loginCaptchaExpires":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotListCategories":[],"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"c_1123912990784966656"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]}},"fetchHost":"www.zhihu.com","subAppName":"column"}</script><script src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/vendor.6c16e03dca561b828324.js.下載"></script><script src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/column.app.744e49a5d85963707511.js.下載"></script><script></script><div><div style="display: none;">想来知乎工作？请发送邮件到 jobs@zhihu.com</div></div><script src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/zap.js.下載"></script><div><div><div class="Editable-languageSuggestions" style="left: -1179px; top: -999px;"><div><div class="Popover"><div class="Editable-languageSuggestionsInput Input-wrapper"><input autocomplete="off" role="combobox" aria-expanded="false" aria-autocomplete="list" aria-activedescendant="AutoComplete11-0" id="Popover10-toggle" aria-haspopup="true" aria-owns="Popover10-content" class="Input" placeholder="选择语言" value=""><div class="Input-after"><svg class="Zi Zi--Select" fill="#afbdcf" viewBox="0 0 24 24" width="24" height="24"><path d="M12 16.183l2.716-2.966a.757.757 0 0 1 1.064.001.738.738 0 0 1 0 1.052l-3.247 3.512a.758.758 0 0 1-1.064 0L8.22 14.27a.738.738 0 0 1 0-1.052.758.758 0 0 1 1.063 0L12 16.183zm0-9.365L9.284 9.782a.758.758 0 0 1-1.064 0 .738.738 0 0 1 0-1.052l3.248-3.512a.758.758 0 0 1 1.065 0L15.78 8.73a.738.738 0 0 1 0 1.052.757.757 0 0 1-1.063.001L12 6.818z" fill-rule="evenodd"></path></svg></div></div></div></div></div></div></div><div id="goog-gt-tt" class="skiptranslate" dir="ltr"><div style="padding: 8px;"><div><div class="logo"><img src="./CNN系列模型发展简述（附github代码——已全部跑通） - 知乎_files/translate_24dp.png" width="20" height="20" alt="Google 翻譯"></div></div></div><div class="top" style="padding: 8px; float: left; width: 100%;"><h1 class="title gray">原文</h1></div><div class="middle" style="padding: 8px;"><div class="original-text"></div></div><div class="bottom" style="padding: 8px;"><div class="activity-links"><span class="activity-link">建議更好的譯法</span><span class="activity-link"></span></div><div class="started-activity-container"><hr style="color: #CCC; background-color: #CCC; height: 1px; border: none;"><div class="activity-root"></div></div></div><div class="status-message" style="display: none;"></div></div><div><div><div></div></div></div><div class="goog-te-spinner-pos"><div class="goog-te-spinner-animation"><svg xmlns="http://www.w3.org/2000/svg" class="goog-te-spinner" width="96px" height="96px" viewBox="0 0 66 66"><circle class="goog-te-spinner-path" fill="none" stroke-width="6" stroke-linecap="round" cx="33" cy="33" r="30"></circle></svg></div></div></body></html>